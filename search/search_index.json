{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bahan Untuk MkDocs \u00b6 Buat dokumentasi project yang indah \u00b6 Materi adalah tema untuk MkDocs , generation situs statis yang sangat baik . menuju dokumentasi proyek, Dibangun menggunakan Google Material Design Pedoman. Quick start \u00b6 Install Material Versi Terbaru Dengan pip : pip install mkdocs-material Tambahkan Baris Berikut Pada Proyek Anda mkdocs.yml : theme : name : 'material' Apa Yang Diharapkan ? \u00b6 Desain responsif dan tata letak untuk semua jenis layar dan perangkat, dirancang untuk melayani dokumentasi proyek Anda dengan cara yang ramah pengguna di 36 bahasa dengan keterbacaan optimal. Mudah primer dan aksen warna, font, favicon, dan logo; pelurusan langsung melalui perluasan tema; terintegrasi dengan Google Analisis, Disqus, dan GitHub. Antarmuka pencarian yang dirancang dengan baik dapat diakses melalui hotkey ( F or S ), pengelompokan hasil pencarian yang cerdas, istilah pencarian menyoroti dan lazy loading. Untuk instruksi terperinci lihat getting started guide . Program Ini Dijalankan Menggunakan : Bahasa Pemrograman ''PYTHON', dengan library : BeatifulSoup4 (install menggunakan pip) request (install menggunakan pip) SQLite3 (Library bawaan Python) csv (Library bawan python) numpy (install menggunakan pip) scipy (install menggunakan pip) scikit-learn (install menggunakan pip, untuk menjalankan install numpy dan scipy) scikit-fuzzy (install menggunakan pip, untuk menjalankan install numpy dan scipy) Target Website Adalah : https://www.liputan6.com/pilpres","title":"Web Mining"},{"location":"#bahan-untuk-mkdocs","text":"","title":"Bahan Untuk MkDocs"},{"location":"#buat-dokumentasi-project-yang-indah","text":"Materi adalah tema untuk MkDocs , generation situs statis yang sangat baik . menuju dokumentasi proyek, Dibangun menggunakan Google Material Design Pedoman.","title":"Buat dokumentasi  project yang indah"},{"location":"#quick-start","text":"Install Material Versi Terbaru Dengan pip : pip install mkdocs-material Tambahkan Baris Berikut Pada Proyek Anda mkdocs.yml : theme : name : 'material'","title":"Quick start"},{"location":"#apa-yang-diharapkan","text":"Desain responsif dan tata letak untuk semua jenis layar dan perangkat, dirancang untuk melayani dokumentasi proyek Anda dengan cara yang ramah pengguna di 36 bahasa dengan keterbacaan optimal. Mudah primer dan aksen warna, font, favicon, dan logo; pelurusan langsung melalui perluasan tema; terintegrasi dengan Google Analisis, Disqus, dan GitHub. Antarmuka pencarian yang dirancang dengan baik dapat diakses melalui hotkey ( F or S ), pengelompokan hasil pencarian yang cerdas, istilah pencarian menyoroti dan lazy loading. Untuk instruksi terperinci lihat getting started guide . Program Ini Dijalankan Menggunakan : Bahasa Pemrograman ''PYTHON', dengan library : BeatifulSoup4 (install menggunakan pip) request (install menggunakan pip) SQLite3 (Library bawaan Python) csv (Library bawan python) numpy (install menggunakan pip) scipy (install menggunakan pip) scikit-learn (install menggunakan pip, untuk menjalankan install numpy dan scipy) scikit-fuzzy (install menggunakan pip, untuk menjalankan install numpy dan scipy) Target Website Adalah : https://www.liputan6.com/pilpres","title":"Apa Yang Diharapkan ?"},{"location":"Text-Extraction/","text":"Text Preprocessing \u00b6 adalah tahapan dimana aplikasi melakukan seleksi data yang akan diproses pada setiap dokumen. Proses preprocessing ini meliputi (1) case folding , (2) tokenizing , (3) filtering , dan (4) stemming . [ Dalam pemrograman python, proses text prepocessing dapat dilakukan dengan menggunakan library Sastrawi, library ini merupakan pengembangan dari library PHP Satrawi, dimana library tersebut dikhususkan untuk text berformat bahasa indonesia. 1. Tokenisasi \u00b6 Tahap Tokenisasi adalah tahap pemotongan string input berdasarkan tiap kata yang menyusunnya. Contoh dari tahap ini dapat dilihat pada gambar dibawah ini. Tokenisasi secara garis besar memecah sekumpulan karakter dalam suatu teks ke dalam satuan kata, bagaimana membedakan karakter-karakter tertentu yang dapat diperlakukan sebagai pemisah kata atau bukan. Sebagai contoh karakter whitespace, seperti enter, tabulasi, spasi dianggap sebagai pemisah kata. Namun untuk karakter petik tunggal (\u2018) , titik (.) , semikolon (;) , titk dua (:) atau lainnya, dapat memiliki peran yang cukup banyak sebagai pemisah kata 2. Filtering \u00b6 Tahap Filtering adalah tahap mengambil kata-kata penting dari hasil token. Bisa menggunakan algoritma stoplist (membuang kata kurang penting) atau wordlist (menyimpan kata penting) . Stoplist/stopword adalah kata-kata yang tidak deskriptif yang dapat dibuang dalam pendekatan bag-of-words. Contoh stopwords adalah \u201cyang\u201d , \u201cdan\u201d , \u201cdi\u201d , \u201cdari\u201d dan seterusnya. Kata-kata seperti \u201cdari\u201d , \u201cyang\u201d , \u201cdi\u201d , dan \u201cke\u201d adalah beberapa contoh kata-kata yang berfrekuensi tinggi dan dapat ditemukan hampir dalam setiap dokumen (disebut sebagai stopword). Penghilangan stopword ini dapat mengurangi ukuran index dan waktu pemrosesan. Selain itu, juga dapat mengurangi level noise. Namun terkadang stopping tidak selalu meningkatkan nilai retrieval. Pembangunan daftar stopword (disebut stoplist) yang kurang hati-hati dapat memperburuk kinerja sistem Information Retrieval (IR) . Belum ada suatu kesimpulan pasti bahwa penggunaan stopping akan selalu meningkatkan nilai retrieval, karena pada beberapa penelitian, hasil yang didapatkan cenderung bervariasi. 3. Steaming \u00b6 Pembuatan indeks dilakukan karena suatu dokumen tidak dapat dikenali langsung oleh suatu Sistem Temu Kembali Informasi atau I**nformation Retrieval System (IRS)**. Oleh karena itu, dokumen tersebut terlebih dahulu perlu dipetakan ke dalam suatu representasi dengan menggunakan teks yang berada di dalamnya. Teknik Stemming diperlukan selain untuk memperkecil jumlah indeks yang berbeda dari suatu dokumen, juga untuk melakukan pengelompokan kata-kata lain yang memiliki kata dasar dan arti yang serupa namun memiliki bentuk atau form yang berbeda karena mendapatkan imbuhan yang berbeda. Sebagai contoh kata bersama, kebersamaan, menyamai, akan distem ke root word-nya yaitu \u201csama\u201d . Namun, seperti halnya stopping, kinerja stemming juga bervariasi dan sering tergantung pada domain bahasa yang digunakan. Proses stemming pada teks berbahasa Indonesia berbeda dengan stemming pada teks berbahasa Inggris. Pada teks berbahasa Inggris, proses yang diperlukan hanya proses menghilangkan sufiks. Sedangkan pada teks berbahasa Indonesia semua kata imbuhan baik itu sufiks dan prefiks juga dihilangkan. def preprosesing ( txt ) : SWfactory = StopWordRemoverFactory () stopword = SWfactory . create_stop_word_remover () stop = stopword . remove ( txt ) Sfactory = StemmerFactory () stemmer = Sfactory . create_stemmer () stem = stemmer . stem ( stop ) return stem def countWord ( txt ) : d = dict () for i in txt . split () : if d.get ( i ) = = None : d [ i ] = txt . count ( i ) return d","title":"Text-Extraction"},{"location":"Text-Extraction/#text-preprocessing","text":"adalah tahapan dimana aplikasi melakukan seleksi data yang akan diproses pada setiap dokumen. Proses preprocessing ini meliputi (1) case folding , (2) tokenizing , (3) filtering , dan (4) stemming . [ Dalam pemrograman python, proses text prepocessing dapat dilakukan dengan menggunakan library Sastrawi, library ini merupakan pengembangan dari library PHP Satrawi, dimana library tersebut dikhususkan untuk text berformat bahasa indonesia.","title":"Text Preprocessing"},{"location":"Text-Extraction/#1-tokenisasi","text":"Tahap Tokenisasi adalah tahap pemotongan string input berdasarkan tiap kata yang menyusunnya. Contoh dari tahap ini dapat dilihat pada gambar dibawah ini. Tokenisasi secara garis besar memecah sekumpulan karakter dalam suatu teks ke dalam satuan kata, bagaimana membedakan karakter-karakter tertentu yang dapat diperlakukan sebagai pemisah kata atau bukan. Sebagai contoh karakter whitespace, seperti enter, tabulasi, spasi dianggap sebagai pemisah kata. Namun untuk karakter petik tunggal (\u2018) , titik (.) , semikolon (;) , titk dua (:) atau lainnya, dapat memiliki peran yang cukup banyak sebagai pemisah kata","title":"1. Tokenisasi"},{"location":"Text-Extraction/#2-filtering","text":"Tahap Filtering adalah tahap mengambil kata-kata penting dari hasil token. Bisa menggunakan algoritma stoplist (membuang kata kurang penting) atau wordlist (menyimpan kata penting) . Stoplist/stopword adalah kata-kata yang tidak deskriptif yang dapat dibuang dalam pendekatan bag-of-words. Contoh stopwords adalah \u201cyang\u201d , \u201cdan\u201d , \u201cdi\u201d , \u201cdari\u201d dan seterusnya. Kata-kata seperti \u201cdari\u201d , \u201cyang\u201d , \u201cdi\u201d , dan \u201cke\u201d adalah beberapa contoh kata-kata yang berfrekuensi tinggi dan dapat ditemukan hampir dalam setiap dokumen (disebut sebagai stopword). Penghilangan stopword ini dapat mengurangi ukuran index dan waktu pemrosesan. Selain itu, juga dapat mengurangi level noise. Namun terkadang stopping tidak selalu meningkatkan nilai retrieval. Pembangunan daftar stopword (disebut stoplist) yang kurang hati-hati dapat memperburuk kinerja sistem Information Retrieval (IR) . Belum ada suatu kesimpulan pasti bahwa penggunaan stopping akan selalu meningkatkan nilai retrieval, karena pada beberapa penelitian, hasil yang didapatkan cenderung bervariasi.","title":"2. Filtering"},{"location":"Text-Extraction/#3-steaming","text":"Pembuatan indeks dilakukan karena suatu dokumen tidak dapat dikenali langsung oleh suatu Sistem Temu Kembali Informasi atau I**nformation Retrieval System (IRS)**. Oleh karena itu, dokumen tersebut terlebih dahulu perlu dipetakan ke dalam suatu representasi dengan menggunakan teks yang berada di dalamnya. Teknik Stemming diperlukan selain untuk memperkecil jumlah indeks yang berbeda dari suatu dokumen, juga untuk melakukan pengelompokan kata-kata lain yang memiliki kata dasar dan arti yang serupa namun memiliki bentuk atau form yang berbeda karena mendapatkan imbuhan yang berbeda. Sebagai contoh kata bersama, kebersamaan, menyamai, akan distem ke root word-nya yaitu \u201csama\u201d . Namun, seperti halnya stopping, kinerja stemming juga bervariasi dan sering tergantung pada domain bahasa yang digunakan. Proses stemming pada teks berbahasa Indonesia berbeda dengan stemming pada teks berbahasa Inggris. Pada teks berbahasa Inggris, proses yang diperlukan hanya proses menghilangkan sufiks. Sedangkan pada teks berbahasa Indonesia semua kata imbuhan baik itu sufiks dan prefiks juga dihilangkan. def preprosesing ( txt ) : SWfactory = StopWordRemoverFactory () stopword = SWfactory . create_stop_word_remover () stop = stopword . remove ( txt ) Sfactory = StemmerFactory () stemmer = Sfactory . create_stemmer () stem = stemmer . stem ( stop ) return stem def countWord ( txt ) : d = dict () for i in txt . split () : if d.get ( i ) = = None : d [ i ] = txt . count ( i ) return d","title":"3. Steaming"},{"location":"authors-notes/","text":"Clustering \u00b6 Pengertian \u00b6 Merupakan proses pengelompokan data menjadi sebuah beberapa kelompok baru, pengelompokan tersebut bisa berdasarkan beberapa ciri yang mirip antar data. Dalam kasus ini ciri yang mirip bisa kita ketahui dari kata yang menjadi ciri dari setiap data / dokumen. Metode \u00b6 K-mean Clustering \u00b6 K-mean Clustering merupakan salah satu algoritma untuk melakukan clustering. Fungsi algoritma ini yaitu untuk membagi data menjadi beberapa kelompok berdasarkan class inputan yang diterima / jumlah kelompok (cluster) yang diinginkan. Algoritma ini akan mengelompokkan data atau objek ke dalam adalah data atau objek kedalam setiap class Tahapan K-mean \u00b6 \u00b6 Menentukan jumlah cluster Memilih K buah titik centroid secara random / acak sebanyak jumlah cluster yang diinginkan pada sebelumnya Mengelompokkan data sehingga terbentuk K buah cluster dengan titik centroid dari setiap cluster merupakan titik centroid yang telah dipilih sebelumnya Memerbaharui nilai titik centroid Mengulangi langkah 3 dan 4 sampai nilai dari titik centroid tidak lagi berubah atau tidak ada perubahan objek pada setiap clas # Clustering kmeans = KMeans ( n_clusters = 5 , random_state = 0 ) . fit ( tfidf_matrix . todense ()) write_csv ( \"Kluster_label.csv\" , [ kmeans . labels_ ]) for i in range ( len ( kmeans . labels_ )): print ( \"Doc %d =>> cluster %d \" % ( i + 1 , kmeans . labels_ [ i ])) *n_cluster menyatakan banyaknya cluster Silhoutte Coefisient \u00b6 \u00b6 Silhoutte Coefisient merupakan salah satu metode yang dilakukan setelah melakukan clustering. Tujuan dari metode ini adalah untuk melihat seberapa cocok data dengan cluster Tahapan Silhoutte \u00b6 \u00b6 Mencari rata-rata jarak objek i dengan objek lainnya di dalam satu cluster (ai) . Mencari rata-rata jarak objek i dengan objek lainnya di seluruh cluster lain, setelah menghitung semuanya, lalu pilih nilai terkecil dari seluruh jarak ke cluster lain (bi) . Setelah itu hitung menggunakan rumus berikut : score = silhouette_score ( df , preds , metric = 'euclidean' ) Implementasi \u00b6 banyak_cluster = list ( range ( 2 , 150 )) for n_cluster in banyak_cluster : clusterer = KMeans ( n_clusters = n_cluster ) preds = clusterer . fit_predict (( df )) centers = clusterer . cluster_centers_ score = silhouette_score ( df , preds , metric = 'euclidean' ) temp . append ( score ) temp_pred . append ( preds ) # print (\"Untuk kluster={},silhoute score :{} \".format(n_cluster, repr(score))) # print(preds) print ( \"kluster terbaik\" ) print ( \"kluster ke > \" + str ( temp . index ( max ( temp )) + 2 ) + \" >silhout> \" + str ( max ( temp ))) Clustering (K-mean) + Feature Selection (Random Forest) \u00b6 def RFE ( cek , n_ranking ): from sklearn.ensemble import RandomForestClassifier from sklearn.feature_selection import RFE rfe = RFE ( RandomForestClassifier ( n_estimators = 50 ), n_features_to_select = 1 ) rfe . fit ( X , y ) scores = [] for i in range ( num_features ): scores . append (( rfe . ranking_ [ i ], X . columns [ i ])) print ( sorted ( scores , reverse = True )) print_best_worst ( scores , n_ranking ) Clustering (K-mean) + Feature Selection (Chi Square). \u00b6 def UFS ( cek , n_ranking ): from sklearn.feature_selection import SelectKBest from sklearn.feature_selection import chi2 , mutual_info_classif print ( \"UFS (Univariate Feature Selection) model chi^2 >>>>>>>\" ) test = SelectKBest ( score_func = chi2 , k = 2 ) test . fit ( X , y ) scores = [] for i in range ( num_features ): score = test . scores_ [ i ] scores . append (( score , X . columns [ i ])) print ( sorted ( scores , reverse = True )) print_best_worst ( scores , n_ranking ) Model Based Ranking model Random Forest \u00b6 def RandomForest (): from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import cross_val_score clf = RandomForestClassifier ( n_estimators = 50 , max_depth = 4 ) scores = [] num_features = len ( X . columns ) for i in range ( num_features ): col = X . columns [ i ] score = np . mean ( cross_val_score ( clf , X [ col ] . values . reshape ( - 1 , 1 ), y , cv = 10 )) scores . append (( int ( score * 100 ), col )) print ( \">>>>>>>>>>>>>>>>>>>>\" ) print ( i , \">\" , col , \"score:\" , score ) Confustion matrix \u00b6 Pada dasarnya, Confusion matrix hampir sama dengan akurasi, namun lebih detail. Jika Akurasi hanya melihat prediksi yang benar, maka confusion matrix melihat prediksi yang benar, dan prediksi yang salah. Misalkan ada dua class \"Merah\" dan \"Biru\". Merah Biru Merah 12 2 Biru 4 15 Misalkan kolom adalah hasil prediksi dan baris merupakan label asli. Maka bisa kita baca seperti ini: sebanyak 12 label \"merah\" diprediksi benar sebagai \"merah\" sebanyak 2 label \"merah\" diprediksi salah sebagai \"biru\" sebanyak 4 label \"biru\" diprediksi salah sebagai \"merah\" sebanyak 15 label \"biru\" diprediksi benar sebagai \"biru\" Code nya sebagai berikut: cm = confusion_matrix ( y_test , predicted ) https://www.researchgate.net/publication/323365687_Algoritme_Genetika_Untuk_Optimasi_K-Means_Clustering_Dalam_Pengelompokan_Data_Tsunami","title":"Clustering"},{"location":"authors-notes/#clustering","text":"","title":"Clustering"},{"location":"authors-notes/#pengertian","text":"Merupakan proses pengelompokan data menjadi sebuah beberapa kelompok baru, pengelompokan tersebut bisa berdasarkan beberapa ciri yang mirip antar data. Dalam kasus ini ciri yang mirip bisa kita ketahui dari kata yang menjadi ciri dari setiap data / dokumen.","title":"Pengertian"},{"location":"authors-notes/#metode","text":"","title":"Metode"},{"location":"authors-notes/#k-mean-clustering","text":"K-mean Clustering merupakan salah satu algoritma untuk melakukan clustering. Fungsi algoritma ini yaitu untuk membagi data menjadi beberapa kelompok berdasarkan class inputan yang diterima / jumlah kelompok (cluster) yang diinginkan. Algoritma ini akan mengelompokkan data atau objek ke dalam adalah data atau objek kedalam setiap class","title":"K-mean Clustering"},{"location":"authors-notes/#tahapan-k-mean","text":"Menentukan jumlah cluster Memilih K buah titik centroid secara random / acak sebanyak jumlah cluster yang diinginkan pada sebelumnya Mengelompokkan data sehingga terbentuk K buah cluster dengan titik centroid dari setiap cluster merupakan titik centroid yang telah dipilih sebelumnya Memerbaharui nilai titik centroid Mengulangi langkah 3 dan 4 sampai nilai dari titik centroid tidak lagi berubah atau tidak ada perubahan objek pada setiap clas # Clustering kmeans = KMeans ( n_clusters = 5 , random_state = 0 ) . fit ( tfidf_matrix . todense ()) write_csv ( \"Kluster_label.csv\" , [ kmeans . labels_ ]) for i in range ( len ( kmeans . labels_ )): print ( \"Doc %d =>> cluster %d \" % ( i + 1 , kmeans . labels_ [ i ])) *n_cluster menyatakan banyaknya cluster","title":"Tahapan K-mean\u00b6"},{"location":"authors-notes/#silhoutte-coefisient","text":"Silhoutte Coefisient merupakan salah satu metode yang dilakukan setelah melakukan clustering. Tujuan dari metode ini adalah untuk melihat seberapa cocok data dengan cluster","title":"Silhoutte Coefisient\u00b6"},{"location":"authors-notes/#tahapan-silhoutte","text":"Mencari rata-rata jarak objek i dengan objek lainnya di dalam satu cluster (ai) . Mencari rata-rata jarak objek i dengan objek lainnya di seluruh cluster lain, setelah menghitung semuanya, lalu pilih nilai terkecil dari seluruh jarak ke cluster lain (bi) . Setelah itu hitung menggunakan rumus berikut : score = silhouette_score ( df , preds , metric = 'euclidean' )","title":"Tahapan Silhoutte\u00b6"},{"location":"authors-notes/#implementasi","text":"banyak_cluster = list ( range ( 2 , 150 )) for n_cluster in banyak_cluster : clusterer = KMeans ( n_clusters = n_cluster ) preds = clusterer . fit_predict (( df )) centers = clusterer . cluster_centers_ score = silhouette_score ( df , preds , metric = 'euclidean' ) temp . append ( score ) temp_pred . append ( preds ) # print (\"Untuk kluster={},silhoute score :{} \".format(n_cluster, repr(score))) # print(preds) print ( \"kluster terbaik\" ) print ( \"kluster ke > \" + str ( temp . index ( max ( temp )) + 2 ) + \" >silhout> \" + str ( max ( temp )))","title":"Implementasi"},{"location":"authors-notes/#clustering-k-mean-feature-selection-random-forest","text":"def RFE ( cek , n_ranking ): from sklearn.ensemble import RandomForestClassifier from sklearn.feature_selection import RFE rfe = RFE ( RandomForestClassifier ( n_estimators = 50 ), n_features_to_select = 1 ) rfe . fit ( X , y ) scores = [] for i in range ( num_features ): scores . append (( rfe . ranking_ [ i ], X . columns [ i ])) print ( sorted ( scores , reverse = True )) print_best_worst ( scores , n_ranking )","title":"Clustering (K-mean) + Feature Selection (Random Forest)"},{"location":"authors-notes/#clustering-k-mean-feature-selection-chi-square","text":"def UFS ( cek , n_ranking ): from sklearn.feature_selection import SelectKBest from sklearn.feature_selection import chi2 , mutual_info_classif print ( \"UFS (Univariate Feature Selection) model chi^2 >>>>>>>\" ) test = SelectKBest ( score_func = chi2 , k = 2 ) test . fit ( X , y ) scores = [] for i in range ( num_features ): score = test . scores_ [ i ] scores . append (( score , X . columns [ i ])) print ( sorted ( scores , reverse = True )) print_best_worst ( scores , n_ranking )","title":"Clustering (K-mean) + Feature Selection (Chi Square)."},{"location":"authors-notes/#model-based-ranking-model-random-forest","text":"def RandomForest (): from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import cross_val_score clf = RandomForestClassifier ( n_estimators = 50 , max_depth = 4 ) scores = [] num_features = len ( X . columns ) for i in range ( num_features ): col = X . columns [ i ] score = np . mean ( cross_val_score ( clf , X [ col ] . values . reshape ( - 1 , 1 ), y , cv = 10 )) scores . append (( int ( score * 100 ), col )) print ( \">>>>>>>>>>>>>>>>>>>>\" ) print ( i , \">\" , col , \"score:\" , score )","title":"Model Based Ranking model Random Forest"},{"location":"authors-notes/#confustion-matrix","text":"Pada dasarnya, Confusion matrix hampir sama dengan akurasi, namun lebih detail. Jika Akurasi hanya melihat prediksi yang benar, maka confusion matrix melihat prediksi yang benar, dan prediksi yang salah. Misalkan ada dua class \"Merah\" dan \"Biru\". Merah Biru Merah 12 2 Biru 4 15 Misalkan kolom adalah hasil prediksi dan baris merupakan label asli. Maka bisa kita baca seperti ini: sebanyak 12 label \"merah\" diprediksi benar sebagai \"merah\" sebanyak 2 label \"merah\" diprediksi salah sebagai \"biru\" sebanyak 4 label \"biru\" diprediksi salah sebagai \"merah\" sebanyak 15 label \"biru\" diprediksi benar sebagai \"biru\" Code nya sebagai berikut: cm = confusion_matrix ( y_test , predicted ) https://www.researchgate.net/publication/323365687_Algoritme_Genetika_Untuk_Optimasi_K-Means_Clustering_Dalam_Pengelompokan_Data_Tsunami","title":"Confustion matrix"},{"location":"compliance/","text":"Vector Space Mode \u00b6 Metode Bag of Words \u00b6 Klasifikasi teks adalah tugas untuk menetapkan kategori yang telah ditentukan ke dokumen teks bebas berdasarkan kontennya. Pendekatan tradisional menggunakan model berbasis unigram untuk klasifikasi teks. Model berbasis Unigram seperti model Bag Of Words (BOW) tidak mempertimbangkan kemunculan set kata di tingkat dokumen. doc 1 : \"Roda saya bundar\" doc 2 : \"Bundar roda saya. Kalau tidak bundar, bukan roda saya\" No Doc Roda Saya Bundar Kalau Tidak Bukan 1 1 1 1 0 0 0 2 2 2 2 1 1 1 Code untuk melakukan perhitungan tersebut adalah sebagai berikut : def countWord ( txt ): d = dict () for i in txt . split (): if d . get ( i ) == None : d [ i ] = txt . count ( i ) return d def add_row_VSM ( d ): VSM . append ([]) for i in VSM [ 0 ]: if d . get ( i ) == None : VSM [ - 1 ] . append ( 0 ) else : VSM [ - 1 ] . append ( d . pop ( i )); for i in d : VSM [ 0 ] . append ( i ) for j in range ( 1 , len ( VSM ) - 1 ): VSM [ j ] . append ( 0 ) VSM [ - 1 ] . append ( d . get ( i )) TF - IDF \u00b6 1. Term Frequecy TF (Term Frequency) adalah frekuensi dari kemunculan sebuah term dalam dokumen yang bersangkutan. Semakin besar jumlah kemunculan suatu term (TF tinggi) dalam dokumen, semakin besar pula bobotnya atau akan memberikan nilai kesesuaian yang semakin besar. Pada Term Frequency (TF) , terdapat beberapa jenis formula yang dapat digunakan: TF biner (binary TF) , hanya memperhatikan apakah suatu kata atau term ada atau tidak dalam dokumen, jika ada diberi nilai satu (1), jika tidak diberi nilai nol (0). TF murni (raw TF) , nilai TF diberikan berdasarkan jumlah kemunculan suatu term di dokumen. Contohnya, jika muncul lima (5) kali maka kata tersebut akan bernilai lima (5). TF logaritmik , hal ini untuk menghindari dominansi dokumen yang mengandung sedikit term dalam query, namun mempunyai frekuensi yang tinggi. Rumus :TF = { 1 + log 10 (Ft,d),} 2. Inverse Document Frequency (IDF) \u00b6 IDF (Inverse Document Frequency) merupakan sebuah perhitungan dari bagaimana term didistribusikan secara luas pada koleksi dokumen yang bersangkutan. IDF menunjukkan hubungan ketersediaan sebuah term dalam seluruh dokumen. Semakin sedikit jumlah dokumen yang mengandung term yang dimaksud, maka nilai IDF semakin besar. Sedangkan untuk Inverse Document Frequency (IDF) dihitung dengan menggunakan formula sebagai berikut: Rumus : IDFj = log(D/dfj) 3. TF-IDV \u00b6 TF-IDV sendiri merupakan kombinasi dari TF (Term Frequence) dengan IDF (Invers Docement Frequence). TF sendiri sama seperti metode Bag of Words yang telah kita hitung sebelumnya yang menyatakan berapa banyak keberadaan suatu term / kata dalam satu dokumen 3 . Sedangkan IDF menunjukkan hubungan ketersediaan sebuah term / kata dalam seluruh dokumen, oleh karena itu kita tinggal menghitung nilai IDF dari setiap Term. TF-IDF sendiri memiliki rumus (TF x IDF). Untuk mendapatkan IDF, pertama kita perlu mencari DF (frekuensi Dokumen). Misalnya: doc1 : Roda Saya Bundar, bundar roda saya doc2 : Bulan itu terlihat bundar Maka, bisa kita ketahui: Kata Jumlah Dokumen yang memiliki kata tersebut Roda 1 Saya 1 Bundar 2 Bulan 1 itu 1 terlihat 1 df = list () total_doc = bow . shape [ 0 ] for kolom in range ( len ( bow [ 0 ])): total = 0 for baris in range ( len ( bow )): if ( bow [ baris , kolom ] > 0 ): total += 1 df . append ( total ) df = np . array ( df ) idf = list () for i in df : tmp = 1 + log10 ( total_doc / ( 1 + i )) idf . append ( tmp ) idf = np . array ( idf ) tfidf = bow * idf https://informatikalogi.com/term-weighting-tf-idf/ https://www.semanticscholar.org/paper/Text-Classification-by-Augmenting-Bag-of-Words-with-SoumyaGeorge-Joseph/f432cbc0e35e6560fc657ad6b490aa07ad901575","title":"Vector Space Mode"},{"location":"compliance/#vector-space-mode","text":"","title":"Vector Space Mode"},{"location":"compliance/#metode-bag-of-words","text":"Klasifikasi teks adalah tugas untuk menetapkan kategori yang telah ditentukan ke dokumen teks bebas berdasarkan kontennya. Pendekatan tradisional menggunakan model berbasis unigram untuk klasifikasi teks. Model berbasis Unigram seperti model Bag Of Words (BOW) tidak mempertimbangkan kemunculan set kata di tingkat dokumen. doc 1 : \"Roda saya bundar\" doc 2 : \"Bundar roda saya. Kalau tidak bundar, bukan roda saya\" No Doc Roda Saya Bundar Kalau Tidak Bukan 1 1 1 1 0 0 0 2 2 2 2 1 1 1 Code untuk melakukan perhitungan tersebut adalah sebagai berikut : def countWord ( txt ): d = dict () for i in txt . split (): if d . get ( i ) == None : d [ i ] = txt . count ( i ) return d def add_row_VSM ( d ): VSM . append ([]) for i in VSM [ 0 ]: if d . get ( i ) == None : VSM [ - 1 ] . append ( 0 ) else : VSM [ - 1 ] . append ( d . pop ( i )); for i in d : VSM [ 0 ] . append ( i ) for j in range ( 1 , len ( VSM ) - 1 ): VSM [ j ] . append ( 0 ) VSM [ - 1 ] . append ( d . get ( i ))","title":"Metode Bag of Words"},{"location":"compliance/#tf-idf","text":"1. Term Frequecy TF (Term Frequency) adalah frekuensi dari kemunculan sebuah term dalam dokumen yang bersangkutan. Semakin besar jumlah kemunculan suatu term (TF tinggi) dalam dokumen, semakin besar pula bobotnya atau akan memberikan nilai kesesuaian yang semakin besar. Pada Term Frequency (TF) , terdapat beberapa jenis formula yang dapat digunakan: TF biner (binary TF) , hanya memperhatikan apakah suatu kata atau term ada atau tidak dalam dokumen, jika ada diberi nilai satu (1), jika tidak diberi nilai nol (0). TF murni (raw TF) , nilai TF diberikan berdasarkan jumlah kemunculan suatu term di dokumen. Contohnya, jika muncul lima (5) kali maka kata tersebut akan bernilai lima (5). TF logaritmik , hal ini untuk menghindari dominansi dokumen yang mengandung sedikit term dalam query, namun mempunyai frekuensi yang tinggi. Rumus :TF = { 1 + log 10 (Ft,d),}","title":"TF - IDF"},{"location":"compliance/#2-inverse-document-frequency-idf","text":"IDF (Inverse Document Frequency) merupakan sebuah perhitungan dari bagaimana term didistribusikan secara luas pada koleksi dokumen yang bersangkutan. IDF menunjukkan hubungan ketersediaan sebuah term dalam seluruh dokumen. Semakin sedikit jumlah dokumen yang mengandung term yang dimaksud, maka nilai IDF semakin besar. Sedangkan untuk Inverse Document Frequency (IDF) dihitung dengan menggunakan formula sebagai berikut: Rumus : IDFj = log(D/dfj)","title":"2. Inverse Document Frequency (IDF)"},{"location":"compliance/#3-tf-idv","text":"TF-IDV sendiri merupakan kombinasi dari TF (Term Frequence) dengan IDF (Invers Docement Frequence). TF sendiri sama seperti metode Bag of Words yang telah kita hitung sebelumnya yang menyatakan berapa banyak keberadaan suatu term / kata dalam satu dokumen 3 . Sedangkan IDF menunjukkan hubungan ketersediaan sebuah term / kata dalam seluruh dokumen, oleh karena itu kita tinggal menghitung nilai IDF dari setiap Term. TF-IDF sendiri memiliki rumus (TF x IDF). Untuk mendapatkan IDF, pertama kita perlu mencari DF (frekuensi Dokumen). Misalnya: doc1 : Roda Saya Bundar, bundar roda saya doc2 : Bulan itu terlihat bundar Maka, bisa kita ketahui: Kata Jumlah Dokumen yang memiliki kata tersebut Roda 1 Saya 1 Bundar 2 Bulan 1 itu 1 terlihat 1 df = list () total_doc = bow . shape [ 0 ] for kolom in range ( len ( bow [ 0 ])): total = 0 for baris in range ( len ( bow )): if ( bow [ baris , kolom ] > 0 ): total += 1 df . append ( total ) df = np . array ( df ) idf = list () for i in df : tmp = 1 + log10 ( total_doc / ( 1 + i )) idf . append ( tmp ) idf = np . array ( idf ) tfidf = bow * idf https://informatikalogi.com/term-weighting-tf-idf/ https://www.semanticscholar.org/paper/Text-Classification-by-Augmenting-Bag-of-Words-with-SoumyaGeorge-Joseph/f432cbc0e35e6560fc657ad6b490aa07ad901575","title":"3. TF-IDV"},{"location":"contributing/","text":"Evaluasi \u00b6 Pada Project ini data yang digunakan oleh narasumber dari website, Berita yang di crawling adalah 59 dokumen, yang terdiri dari judul dan isi berita. [ table view [","title":"Evaluasi"},{"location":"contributing/#evaluasi","text":"Pada Project ini data yang digunakan oleh narasumber dari website, Berita yang di crawling adalah 59 dokumen, yang terdiri dari judul dan isi berita. [ table view [","title":"Evaluasi"},{"location":"crawler/","text":"Crawler \u00b6 Web Crawler \u00b6 adalah sebuah program dengan metode tertentu yang berfungsi untuk melakukan Scan atau crawl ke semua halaman internet untuk mencari data yang diinginkan. Data tersebut merupakan hasil teratas dari mesin pencari google dan yahoo. Web Crawler atau web spider, web robot, bot crawl dan automathic indeker. Web clawer memiliki beberapa maafaat dan tujuan tetapi penggunaan yang paling umum digunakan sebagai search engine. Search engine merupakan sebuah tool yang berfungsi sebagai mesin pencari seperti google. Ilustrasi : [ Berikut Code untuk melakukan Crawling : \u00b6 def crawl ( src ): global c page = requests . get ( src ) # Mengubah html ke object beautiful soup soup = BeautifulSoup ( page . content , 'html.parser' ) # Find all item items = soup . findAll ( class_ = 'article-item' ) #print ('Proses : %.2f' %((c/maxPage)*100) + '%'); c+=1 for item in items : judul = item . find ( class_ = 'title-article' ) . getText () authors = item . find ( class_ = \"author-article\" ) . findAll ( class_ = 'title-author' ) author = '' for i in authors : author = author + i . getText () + '; ' abstrack = item . find ( class_ = 'article-abstract' ) . find ( 'p' ) . getText () #pengecekan data redundant cursor = conn . execute ( 'select * from jurnal2 where judul=?' , ( judul ,)) cursor = cursor . fetchall () if ( len ( cursor ) == 0 ): conn . execute ( \"INSERT INTO jurnal2 \\ VALUES (?, ?, ?, ?)\" , ( judul , author , abstrack , kategori )); Blockquotes \u00b6 Perlu diingat bahwa, setiap web memiliki struktur html yang berbeda , maka jika kalian mengubah url web, maka perlu dilakukan penyesuaian pada code. Selanjutnya, Untuk mendapatkan tag html .yang diinginkan BeautifulSoup menyediakan 2 fungsi, yaitu : soup.find(parameter) digunakan untuk mendapatkan satu tag html yang muncul pertama kali. Hasilnya berupa objek soup soup.findAll(parameter) digunakan untuk mendapatkan semua tag html tersebut. Hasilnya berupa list Sementara itu , untuk parameternya memiliki 3 macam. Kalian bisa mencari berdasarkan: tag html (seperti <p> , <div> , h1 dsb). contoh: code html <div><p>Saya Suka Coding</p></div> maka, untuk mendapatkan tag p adalah : soup.find(\"p\") class code html <div><p class='Suka'>Saya Suka Coding</p></div> maka, untuk mendapatkan tag p adalah : soup.find(class_='Suka') id code html <div><p id='Coding'>Saya Suka Coding</p></div> maka, untuk mendapatkan tag p adalah : soup.find(id='Coding') Kemudian , untuk mendapatkan textnya, digunakan .getText() pada objek BeautifulSoup. Setelah paham tentang bagaimana menggunakan library beautifulsoup, Selanjutnya akan membahas bagaimana code di atas bekerja. items = soup . findAll ( class_ = 'article-item' ) Hal pertama yang kita lakukan adalah menentukan apa saja yang akan kita ambil. Pada kasus jurnal online ini, kita hanya akan mengambil judul, penulis, beserta abstraknya saja. Untuk itu, di sini kita mengambil semua paper, yang bisa kita lihat berada di class 'article-item'. for item in items : judul = item . find ( class_ = 'title-article' ) . getText () authors = item . find ( class_ = \"author-article\" ) . findAll ( class_ = 'title-author' ) author = '' for i in authors : author = author + i . getText () + '; ' abstrack = item . find ( class_ = 'article-abstract' ) . find ( 'p' ) . getText () Kemudian, untuk setiap paper, ambil judul (dengan class 'title-article'), penulis (dengan class 'author-article'), dan abstrak (dengan class 'article-abstract', lantas dicari tag p) #pengecekan data redundant cursor = conn . execute ( 'select * from jurnal2 where judul=?' , ( judul ,)) cursor = cursor . fetchall () if ( len ( cursor ) == 0 ): conn . execute ( \"INSERT INTO jurnal2 \\ VALUES (?, ?, ?, ?)\" , ( judul , author , abstrack , kategori )); Kemudian, memasukkan ke dalam database. Sebelum itu, perlu dilakukan pengecekan apakah ada data yang sama. Karena hal itu bisa mengganggu hasil akhir nanti.","title":"Crawler"},{"location":"crawler/#crawler","text":"","title":"Crawler"},{"location":"crawler/#web-crawler","text":"adalah sebuah program dengan metode tertentu yang berfungsi untuk melakukan Scan atau crawl ke semua halaman internet untuk mencari data yang diinginkan. Data tersebut merupakan hasil teratas dari mesin pencari google dan yahoo. Web Crawler atau web spider, web robot, bot crawl dan automathic indeker. Web clawer memiliki beberapa maafaat dan tujuan tetapi penggunaan yang paling umum digunakan sebagai search engine. Search engine merupakan sebuah tool yang berfungsi sebagai mesin pencari seperti google. Ilustrasi : [","title":"Web Crawler"},{"location":"crawler/#berikut-code-untuk-melakukan-crawling","text":"def crawl ( src ): global c page = requests . get ( src ) # Mengubah html ke object beautiful soup soup = BeautifulSoup ( page . content , 'html.parser' ) # Find all item items = soup . findAll ( class_ = 'article-item' ) #print ('Proses : %.2f' %((c/maxPage)*100) + '%'); c+=1 for item in items : judul = item . find ( class_ = 'title-article' ) . getText () authors = item . find ( class_ = \"author-article\" ) . findAll ( class_ = 'title-author' ) author = '' for i in authors : author = author + i . getText () + '; ' abstrack = item . find ( class_ = 'article-abstract' ) . find ( 'p' ) . getText () #pengecekan data redundant cursor = conn . execute ( 'select * from jurnal2 where judul=?' , ( judul ,)) cursor = cursor . fetchall () if ( len ( cursor ) == 0 ): conn . execute ( \"INSERT INTO jurnal2 \\ VALUES (?, ?, ?, ?)\" , ( judul , author , abstrack , kategori ));","title":"Berikut Code untuk melakukan Crawling :"},{"location":"crawler/#blockquotes","text":"Perlu diingat bahwa, setiap web memiliki struktur html yang berbeda , maka jika kalian mengubah url web, maka perlu dilakukan penyesuaian pada code. Selanjutnya, Untuk mendapatkan tag html .yang diinginkan BeautifulSoup menyediakan 2 fungsi, yaitu : soup.find(parameter) digunakan untuk mendapatkan satu tag html yang muncul pertama kali. Hasilnya berupa objek soup soup.findAll(parameter) digunakan untuk mendapatkan semua tag html tersebut. Hasilnya berupa list Sementara itu , untuk parameternya memiliki 3 macam. Kalian bisa mencari berdasarkan: tag html (seperti <p> , <div> , h1 dsb). contoh: code html <div><p>Saya Suka Coding</p></div> maka, untuk mendapatkan tag p adalah : soup.find(\"p\") class code html <div><p class='Suka'>Saya Suka Coding</p></div> maka, untuk mendapatkan tag p adalah : soup.find(class_='Suka') id code html <div><p id='Coding'>Saya Suka Coding</p></div> maka, untuk mendapatkan tag p adalah : soup.find(id='Coding') Kemudian , untuk mendapatkan textnya, digunakan .getText() pada objek BeautifulSoup. Setelah paham tentang bagaimana menggunakan library beautifulsoup, Selanjutnya akan membahas bagaimana code di atas bekerja. items = soup . findAll ( class_ = 'article-item' ) Hal pertama yang kita lakukan adalah menentukan apa saja yang akan kita ambil. Pada kasus jurnal online ini, kita hanya akan mengambil judul, penulis, beserta abstraknya saja. Untuk itu, di sini kita mengambil semua paper, yang bisa kita lihat berada di class 'article-item'. for item in items : judul = item . find ( class_ = 'title-article' ) . getText () authors = item . find ( class_ = \"author-article\" ) . findAll ( class_ = 'title-author' ) author = '' for i in authors : author = author + i . getText () + '; ' abstrack = item . find ( class_ = 'article-abstract' ) . find ( 'p' ) . getText () Kemudian, untuk setiap paper, ambil judul (dengan class 'title-article'), penulis (dengan class 'author-article'), dan abstrak (dengan class 'article-abstract', lantas dicari tag p) #pengecekan data redundant cursor = conn . execute ( 'select * from jurnal2 where judul=?' , ( judul ,)) cursor = cursor . fetchall () if ( len ( cursor ) == 0 ): conn . execute ( \"INSERT INTO jurnal2 \\ VALUES (?, ?, ?, ?)\" , ( judul , author , abstrack , kategori )); Kemudian, memasukkan ke dalam database. Sebelum itu, perlu dilakukan pengecekan apakah ada data yang sama. Karena hal itu bisa mengganggu hasil akhir nanti.","title":"Blockquotes"},{"location":"getting-started/","text":"Getting started \u00b6 Installation \u00b6 Installing MkDocs \u00b6 Before installing MkDocs , you need to make sure you have Python and pip \u2013 the Python package manager \u2013 up and running. You can verify if you're already good to go with the following commands: python --version # Python 3.7.3 pip --version # pip 9.0.1 Installing and verifying MkDocs is as simple as: pip install mkdocs && mkdocs --version # mkdocs, version 0.17.1 Material requires MkDocs >= 0.17.1. Installing Material \u00b6 using pip \u00b6 Material can be installed with pip : pip install mkdocs-material using choco \u00b6 If you're on Windows you can use Chocolatey to install Material : choco install mkdocs-material This will install all required dependencies like Python and MkDocs . cloning from GitHub \u00b6 Material can also be used without a system-wide installation by cloning the repository into a subfolder of your project's root directory: git clone https://github.com/squidfunk/mkdocs-material.git This is especially useful if you want to extend the theme and override some parts of the theme. The theme will reside in the folder mkdocs-material/material . Troubleshooting \u00b6 Installation on macOS When you're running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this: Installing in user space (recommended): Provide the --user flag to the install command and pip will install the package in a user-site location. This is the recommended way. Switching to a homebrewed Python : Upgrade your Python installation to a self-contained solution by installing Python with Homebrew. This should eliminate a lot of problems you may be having with pip . Error: unrecognized theme 'material' If you run into this error, the most common reason is that you installed MkDocs through some package manager (e.g. Homebrew or apt-get ) and the Material theme through pip , so both packages end up in different locations. MkDocs only checks its install location for themes. Alternative: Using Docker \u00b6 If you're familiar with Docker, the official Docker image for Material comes with all dependencies pre-installed and ready-to-use with the latest version published on PyPI, packaged in a very small image. Pull it with: docker pull squidfunk/mkdocs-material The mkdocs executable is provided as an entrypoint, serve is the default command. Start the development server in your project root with: docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material If you're using Windows command prompt ( cmd.exe ), substitute ${PWD} with \"%cd%\" . Usage \u00b6 In order to enable the theme just add one of the following lines to your project's mkdocs.yml . If you installed Material using a package manager: theme : name : 'material' If you cloned Material from GitHub: theme : name : null custom_dir : 'mkdocs-material/material' MkDocs includes a development server, so you can review your changes as you go. The development server can be started with the following command: mkdocs serve Now you can point your browser to http://localhost:8000 and the Material theme should be visible. From here on, you can start writing your documentation, or read on and customize the theme. Configuration \u00b6 Color palette \u00b6 A default hue is defined for every primary and accent color on Google's Material Design color palette , which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set. See the guide on customization for more information. Primary colors \u00b6 Default: Indigo Click on a tile to change the primary color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange Brown Grey Blue Grey White var buttons = document.querySelectorAll(\"button[data-md-color-primary]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary; }) }) Accent colors \u00b6 Default: Indigo Click on a tile to change the accent color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorAccent = this.dataset.mdColorAccent; }) }) Font family \u00b6 Default: Roboto and Roboto Mono By default the Roboto font family is included with the theme, specifically the regular sans-serif type for text and the monospaced type for code. Both fonts are loaded from Google Fonts and can be changed to other fonts, like for example the Ubuntu font family : theme : font : text : 'Ubuntu' code : 'Ubuntu Mono' The text font will be loaded in weights 400 and 700 , the monospaced font in regular weight. If you want to load fonts from other destinations or don't want to use the Google Fonts loading magic, just set font to false : theme : font : false Logo \u00b6 Default icon: school Your logo should have rectangular shape with a minimum resolution of 128x128, leave some room towards the edges and be composed of high contrast areas on a transparent ground, as it will be placed on the colored header bar and drawer. Simply create the folder docs/images , add your logo and embed it with: theme : logo : 'images/logo.svg' Additionally, the default icon can be changed by setting an arbitrary ligature (or Unicode code point) from the Material Design icon font , e.g. theme : logo : icon : 'cloud' Language \u00b6 Call for Contributions: Add languages/translations to Material Help translate Material into more languages - it's just one click and takes approximately 2 minutes : click here Localization \u00b6 Default: en Material for MkDocs supports internationalization (i18n) and provides translations for all template variables and labels in the following languages: Available languages ar / Arabic ca / Catalan cs / Czech da / Danish nl / Dutch en / English fi / Finnish fr / French gl / Galician de / German gr / Greek he / Hebrew hi / Hindi hr / Croatian hu / Hungarian id / Indonesian it / Italian ja / Japanese kr / Korean no / Norwegian nn / Norwegian (Nynorsk) fa / Persian pl / Polish pt / Portugese ru / Russian sr / Serbian sh / Serbo-Croatian sk / Slovak es / Spanish sv / Swedish tr / Turkish uk / Ukrainian vi / Vietnamese zh / Chinese (Simplified) zh-Hant / Chinese (Traditional) zh-TW / Chinese (Taiwanese) Submit a new language Specify the language with: theme : language : 'id' If the language is not specified, Material falls back to English. To create a translation for another language, copy the localization file of an existing language, name the new file using the 2-letter language code and adjust all translations: cp partials/language/en.html partials/language/jp.html Text direction \u00b6 Default: best match for given theme language, automatically set Material supports both, left-to-right ( ltr ) and right-to-left ( rtl ) text direction. This enables more languages like Arabic, Hebrew, Syriac and others to be used with the theme: theme : direction : 'rtl' Site search \u00b6 Default: best match for given theme language, automatically set Site search is implemented using lunr.js , which includes stemmers for the English language by default, while stemmers for other languages are included with lunr-languages , both of which are integrated with this theme. Material selects the matching (or best-matching) stemmer for the given theme language. Multilingual search can be activated in your project's mkdocs.yml by explicitly defining the search language(s): extra : search : language : 'en, de, ru' At the time of writing, the following languages are supported: Available language stemmers da / Danish du / Dutch en / English fi / Finnish fr / French de / German hu / Hungarian it / Italian ja / Japanese no / Norwegian pt / Portugese ro / Romanian ru / Russian es / Spanish sv / Swedish tr / Turkish MkDocs 1.0 compatibility While MkDocs 1.0 supports prebuilding the search index, Material currently doesn't support this setting as the default search behavior of the original theme was heavily modified for the sake of a better UX. Integration is possible, but a small subset of the features Material provides will not be portable to the prebuilt index mainly due to missing localization. Only specify the languages you really need Be aware that including support for other languages increases the general JavaScript payload by around 20kb (without gzip) and by another 15-30kb per language. The separator for tokenization can be customized which makes it possible to index parts of words that are separated by - or . : extra : search : tokenizer : '[\\s\\-\\.]+' Favicon \u00b6 Default: assets/images/favicon.png The default favicon can be changed by setting the favicon variable to an .ico or image file: theme : favicon : 'assets/images/logo-universitas-trunojoyo-madura.png' Features \u00b6 Tabs \u00b6 Default: false By default, the entire navigation is rendered on the left side using collapsible sections (different from the default MkDocs theme which renders the top-level sections in the header), because horizontal navigation is often problematic on smaller screens. However, for large documentation projects it's sometimes desirable to add another navigation layer to separate top-level sections. Material achieves this with the tabs feature, which can be enabled by setting the respective feature flag to true : theme : feature : tabs : true When tabs are enabled, top-level sections will be rendered in an additional layer directly below the header. The navigation on the left side will only include the pages contained within the selected section. Furthermore, top-level pages defined inside your project's mkdocs.yml will be grouped under the first tab which will receive the title of the first page. Customization \u00b6 Adding a source repository \u00b6 To include a link to the repository of your project within your documentation, set the following variables via your project's mkdocs.yml : repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' The name of the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Furthermore, if repo_url points to a GitHub, BitBucket or GitLab repository, the respective service logo will be shown next to the name of the repository. Additionally, for GitHub, the number of stars and forks is shown. If the repository is hosted in a private environment, the service logo can be set explicitly by setting extra.repo_icon to github , gitlab or bitbucket . Why is there an edit button at the top of every article? If the repo_url is set to a GitHub or BitBucket repository, and the repo_name is set to GitHub or BitBucket (implied by default), an edit button will appear at the top of every article. This is the automatic behavior that MkDocs implements. See the MkDocs documentation on more guidance regarding the edit_uri attribute, which defines whether the edit button is shown or not. Adding social links \u00b6 Social accounts can be linked in the footer of the documentation using the automatically included FontAwesome webfont. The type must denote the name of the social service, e.g. github , twitter or linkedin and the link must contain the URL you want to link to: extra : social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://linkedin.com/in/squidfunk' The links are generated in order and the type of the links must match the name of the FontAwesome glyph. The fa is automatically added, so github will result in fa fa-github . Adding a Web App Manifest \u00b6 A Web App Manifest is a simple JSON file that tells the browser about your web application and how it should behave when installed on the user's mobile device or desktop. You can specify a manifest in your mkdocs.yml : extra : manifest : 'manifest.webmanifest' More advanced customization \u00b6 If you want to change the general appearance of the Material theme, see this article for more information on advanced customization. Integrations \u00b6 Google Analytics \u00b6 MkDocs makes it easy to integrate site tracking with Google Analytics. Besides basic tracking, clicks on all outgoing links can be tracked as well as how site search is used. Tracking can be activated in your project's mkdocs.yml : google_analytics : - 'UA-XXXXXXXX-X' - 'auto' Disqus \u00b6 Material for MkDocs is integrated with Disqus , so if you want to add a comments section to your documentation set the shortname of your Disqus project in your mkdocs.yml : extra : disqus : 'your-shortname' The comments section is inserted on every page, except the index page . Additionally, a new entry at the bottom of the table of contents is generated that is linking to the comments section. The necessary JavaScript is automatically included. Requirements site_url value must be set in mkdocs.yml for the Disqus integration to load properly. Disqus can also be enabled or disabled for specific pages using Metadata . Extensions \u00b6 MkDocs supports several Markdown extensions . The following extensions are not enabled by default (see the link for which are enabled by default) but highly recommended, so they should be switched on at all times: markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true For more information, see the following list of extensions supported by the Material theme including more information regarding installation and usage: Admonition Codehilite Footnotes Metadata Permalinks PyMdown Extensions Full example \u00b6 Below is a full example configuration for a mkdocs.yml : # Project information site_name : 'Penambangan WEB' site_description : 'A Material Design theme for MkDocs' site_author : 'Martin Donath' site_url : 'https://squidfunk.github.io/mkdocs-material/' # Repository repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' # Copyright copyright : 'Copyright &copy; 2016 - 2017 Martin Donath' # Configuration theme : name : 'material' language : 'en' palette : primary : 'indigo' accent : 'indigo' font : text : 'Times New Roman' code : 'Times New Roman' # Customization extra : manifest : 'manifest.webmanifest' social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://linkedin.com/in/squidfunk' # Google Analytics google_analytics : - 'UA-XXXXXXXX-X' - 'auto' # Extensions markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true","title":"Getting started"},{"location":"getting-started/#getting-started","text":"","title":"Getting started"},{"location":"getting-started/#installation","text":"","title":"Installation"},{"location":"getting-started/#installing-mkdocs","text":"Before installing MkDocs , you need to make sure you have Python and pip \u2013 the Python package manager \u2013 up and running. You can verify if you're already good to go with the following commands: python --version # Python 3.7.3 pip --version # pip 9.0.1 Installing and verifying MkDocs is as simple as: pip install mkdocs && mkdocs --version # mkdocs, version 0.17.1 Material requires MkDocs >= 0.17.1.","title":"Installing MkDocs"},{"location":"getting-started/#installing-material","text":"","title":"Installing Material"},{"location":"getting-started/#using-pip","text":"Material can be installed with pip : pip install mkdocs-material","title":"using pip"},{"location":"getting-started/#using-choco","text":"If you're on Windows you can use Chocolatey to install Material : choco install mkdocs-material This will install all required dependencies like Python and MkDocs .","title":"using choco"},{"location":"getting-started/#cloning-from-github","text":"Material can also be used without a system-wide installation by cloning the repository into a subfolder of your project's root directory: git clone https://github.com/squidfunk/mkdocs-material.git This is especially useful if you want to extend the theme and override some parts of the theme. The theme will reside in the folder mkdocs-material/material .","title":"cloning from GitHub"},{"location":"getting-started/#troubleshooting","text":"Installation on macOS When you're running the pre-installed version of Python on macOS, pip tries to install packages in a folder for which your user might not have the adequate permissions. There are two possible solutions for this: Installing in user space (recommended): Provide the --user flag to the install command and pip will install the package in a user-site location. This is the recommended way. Switching to a homebrewed Python : Upgrade your Python installation to a self-contained solution by installing Python with Homebrew. This should eliminate a lot of problems you may be having with pip . Error: unrecognized theme 'material' If you run into this error, the most common reason is that you installed MkDocs through some package manager (e.g. Homebrew or apt-get ) and the Material theme through pip , so both packages end up in different locations. MkDocs only checks its install location for themes.","title":"Troubleshooting"},{"location":"getting-started/#alternative-using-docker","text":"If you're familiar with Docker, the official Docker image for Material comes with all dependencies pre-installed and ready-to-use with the latest version published on PyPI, packaged in a very small image. Pull it with: docker pull squidfunk/mkdocs-material The mkdocs executable is provided as an entrypoint, serve is the default command. Start the development server in your project root with: docker run --rm -it -p 8000:8000 -v ${PWD}:/docs squidfunk/mkdocs-material If you're using Windows command prompt ( cmd.exe ), substitute ${PWD} with \"%cd%\" .","title":"Alternative: Using Docker"},{"location":"getting-started/#usage","text":"In order to enable the theme just add one of the following lines to your project's mkdocs.yml . If you installed Material using a package manager: theme : name : 'material' If you cloned Material from GitHub: theme : name : null custom_dir : 'mkdocs-material/material' MkDocs includes a development server, so you can review your changes as you go. The development server can be started with the following command: mkdocs serve Now you can point your browser to http://localhost:8000 and the Material theme should be visible. From here on, you can start writing your documentation, or read on and customize the theme.","title":"Usage"},{"location":"getting-started/#configuration","text":"","title":"Configuration"},{"location":"getting-started/#color-palette","text":"A default hue is defined for every primary and accent color on Google's Material Design color palette , which makes it very easy to change the overall look of the theme. Just set the primary and accent colors using the following variables: theme : palette : primary : 'indigo' accent : 'indigo' Color names are case-insensitive, but must match the names of the Material Design color palette. Valid values are: red , pink , purple , deep purple , indigo , blue , light blue , cyan , teal , green , light green , lime , yellow , amber , orange , deep orange , brown , grey , blue grey and white . The last four colors can only be used as a primary color. If the color is set via this configuration, an additional CSS file that defines the color palette is automatically included. If you want to keep things lean, clone the repository and recompile the theme with your custom colors set. See the guide on customization for more information.","title":"Color palette"},{"location":"getting-started/#primary-colors","text":"Default: Indigo Click on a tile to change the primary color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange Brown Grey Blue Grey White var buttons = document.querySelectorAll(\"button[data-md-color-primary]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorPrimary = this.dataset.mdColorPrimary; }) })","title":"Primary colors"},{"location":"getting-started/#accent-colors","text":"Default: Indigo Click on a tile to change the accent color of the theme: Red Pink Purple Deep Purple Indigo Blue Light Blue Cyan Teal Green Light Green Lime Yellow Amber Orange Deep Orange var buttons = document.querySelectorAll(\"button[data-md-color-accent]\"); Array.prototype.forEach.call(buttons, function(button) { button.addEventListener(\"click\", function() { document.body.dataset.mdColorAccent = this.dataset.mdColorAccent; }) })","title":"Accent colors"},{"location":"getting-started/#font-family","text":"Default: Roboto and Roboto Mono By default the Roboto font family is included with the theme, specifically the regular sans-serif type for text and the monospaced type for code. Both fonts are loaded from Google Fonts and can be changed to other fonts, like for example the Ubuntu font family : theme : font : text : 'Ubuntu' code : 'Ubuntu Mono' The text font will be loaded in weights 400 and 700 , the monospaced font in regular weight. If you want to load fonts from other destinations or don't want to use the Google Fonts loading magic, just set font to false : theme : font : false","title":"Font family"},{"location":"getting-started/#logo","text":"Default icon: school Your logo should have rectangular shape with a minimum resolution of 128x128, leave some room towards the edges and be composed of high contrast areas on a transparent ground, as it will be placed on the colored header bar and drawer. Simply create the folder docs/images , add your logo and embed it with: theme : logo : 'images/logo.svg' Additionally, the default icon can be changed by setting an arbitrary ligature (or Unicode code point) from the Material Design icon font , e.g. theme : logo : icon : 'cloud'","title":"Logo"},{"location":"getting-started/#language","text":"Call for Contributions: Add languages/translations to Material Help translate Material into more languages - it's just one click and takes approximately 2 minutes : click here","title":"Language"},{"location":"getting-started/#localization","text":"Default: en Material for MkDocs supports internationalization (i18n) and provides translations for all template variables and labels in the following languages: Available languages ar / Arabic ca / Catalan cs / Czech da / Danish nl / Dutch en / English fi / Finnish fr / French gl / Galician de / German gr / Greek he / Hebrew hi / Hindi hr / Croatian hu / Hungarian id / Indonesian it / Italian ja / Japanese kr / Korean no / Norwegian nn / Norwegian (Nynorsk) fa / Persian pl / Polish pt / Portugese ru / Russian sr / Serbian sh / Serbo-Croatian sk / Slovak es / Spanish sv / Swedish tr / Turkish uk / Ukrainian vi / Vietnamese zh / Chinese (Simplified) zh-Hant / Chinese (Traditional) zh-TW / Chinese (Taiwanese) Submit a new language Specify the language with: theme : language : 'id' If the language is not specified, Material falls back to English. To create a translation for another language, copy the localization file of an existing language, name the new file using the 2-letter language code and adjust all translations: cp partials/language/en.html partials/language/jp.html","title":"Localization"},{"location":"getting-started/#text-direction","text":"Default: best match for given theme language, automatically set Material supports both, left-to-right ( ltr ) and right-to-left ( rtl ) text direction. This enables more languages like Arabic, Hebrew, Syriac and others to be used with the theme: theme : direction : 'rtl'","title":"Text direction"},{"location":"getting-started/#site-search","text":"Default: best match for given theme language, automatically set Site search is implemented using lunr.js , which includes stemmers for the English language by default, while stemmers for other languages are included with lunr-languages , both of which are integrated with this theme. Material selects the matching (or best-matching) stemmer for the given theme language. Multilingual search can be activated in your project's mkdocs.yml by explicitly defining the search language(s): extra : search : language : 'en, de, ru' At the time of writing, the following languages are supported: Available language stemmers da / Danish du / Dutch en / English fi / Finnish fr / French de / German hu / Hungarian it / Italian ja / Japanese no / Norwegian pt / Portugese ro / Romanian ru / Russian es / Spanish sv / Swedish tr / Turkish MkDocs 1.0 compatibility While MkDocs 1.0 supports prebuilding the search index, Material currently doesn't support this setting as the default search behavior of the original theme was heavily modified for the sake of a better UX. Integration is possible, but a small subset of the features Material provides will not be portable to the prebuilt index mainly due to missing localization. Only specify the languages you really need Be aware that including support for other languages increases the general JavaScript payload by around 20kb (without gzip) and by another 15-30kb per language. The separator for tokenization can be customized which makes it possible to index parts of words that are separated by - or . : extra : search : tokenizer : '[\\s\\-\\.]+'","title":"Site search"},{"location":"getting-started/#favicon","text":"Default: assets/images/favicon.png The default favicon can be changed by setting the favicon variable to an .ico or image file: theme : favicon : 'assets/images/logo-universitas-trunojoyo-madura.png'","title":"Favicon"},{"location":"getting-started/#features","text":"","title":"Features"},{"location":"getting-started/#tabs","text":"Default: false By default, the entire navigation is rendered on the left side using collapsible sections (different from the default MkDocs theme which renders the top-level sections in the header), because horizontal navigation is often problematic on smaller screens. However, for large documentation projects it's sometimes desirable to add another navigation layer to separate top-level sections. Material achieves this with the tabs feature, which can be enabled by setting the respective feature flag to true : theme : feature : tabs : true When tabs are enabled, top-level sections will be rendered in an additional layer directly below the header. The navigation on the left side will only include the pages contained within the selected section. Furthermore, top-level pages defined inside your project's mkdocs.yml will be grouped under the first tab which will receive the title of the first page.","title":"Tabs"},{"location":"getting-started/#customization","text":"","title":"Customization"},{"location":"getting-started/#adding-a-source-repository","text":"To include a link to the repository of your project within your documentation, set the following variables via your project's mkdocs.yml : repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' The name of the repository will be rendered next to the search bar on big screens and as part of the main navigation drawer on smaller screen sizes. Furthermore, if repo_url points to a GitHub, BitBucket or GitLab repository, the respective service logo will be shown next to the name of the repository. Additionally, for GitHub, the number of stars and forks is shown. If the repository is hosted in a private environment, the service logo can be set explicitly by setting extra.repo_icon to github , gitlab or bitbucket . Why is there an edit button at the top of every article? If the repo_url is set to a GitHub or BitBucket repository, and the repo_name is set to GitHub or BitBucket (implied by default), an edit button will appear at the top of every article. This is the automatic behavior that MkDocs implements. See the MkDocs documentation on more guidance regarding the edit_uri attribute, which defines whether the edit button is shown or not.","title":"Adding a source repository"},{"location":"getting-started/#adding-social-links","text":"Social accounts can be linked in the footer of the documentation using the automatically included FontAwesome webfont. The type must denote the name of the social service, e.g. github , twitter or linkedin and the link must contain the URL you want to link to: extra : social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://linkedin.com/in/squidfunk' The links are generated in order and the type of the links must match the name of the FontAwesome glyph. The fa is automatically added, so github will result in fa fa-github .","title":"Adding social links"},{"location":"getting-started/#adding-a-web-app-manifest","text":"A Web App Manifest is a simple JSON file that tells the browser about your web application and how it should behave when installed on the user's mobile device or desktop. You can specify a manifest in your mkdocs.yml : extra : manifest : 'manifest.webmanifest'","title":"Adding a Web App Manifest"},{"location":"getting-started/#more-advanced-customization","text":"If you want to change the general appearance of the Material theme, see this article for more information on advanced customization.","title":"More advanced customization"},{"location":"getting-started/#integrations","text":"","title":"Integrations"},{"location":"getting-started/#google-analytics","text":"MkDocs makes it easy to integrate site tracking with Google Analytics. Besides basic tracking, clicks on all outgoing links can be tracked as well as how site search is used. Tracking can be activated in your project's mkdocs.yml : google_analytics : - 'UA-XXXXXXXX-X' - 'auto'","title":"Google Analytics"},{"location":"getting-started/#disqus","text":"Material for MkDocs is integrated with Disqus , so if you want to add a comments section to your documentation set the shortname of your Disqus project in your mkdocs.yml : extra : disqus : 'your-shortname' The comments section is inserted on every page, except the index page . Additionally, a new entry at the bottom of the table of contents is generated that is linking to the comments section. The necessary JavaScript is automatically included. Requirements site_url value must be set in mkdocs.yml for the Disqus integration to load properly. Disqus can also be enabled or disabled for specific pages using Metadata .","title":"Disqus"},{"location":"getting-started/#extensions","text":"MkDocs supports several Markdown extensions . The following extensions are not enabled by default (see the link for which are enabled by default) but highly recommended, so they should be switched on at all times: markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true For more information, see the following list of extensions supported by the Material theme including more information regarding installation and usage: Admonition Codehilite Footnotes Metadata Permalinks PyMdown Extensions","title":"Extensions"},{"location":"getting-started/#full-example","text":"Below is a full example configuration for a mkdocs.yml : # Project information site_name : 'Penambangan WEB' site_description : 'A Material Design theme for MkDocs' site_author : 'Martin Donath' site_url : 'https://squidfunk.github.io/mkdocs-material/' # Repository repo_name : 'squidfunk/mkdocs-material' repo_url : 'https://github.com/squidfunk/mkdocs-material' # Copyright copyright : 'Copyright &copy; 2016 - 2017 Martin Donath' # Configuration theme : name : 'material' language : 'en' palette : primary : 'indigo' accent : 'indigo' font : text : 'Times New Roman' code : 'Times New Roman' # Customization extra : manifest : 'manifest.webmanifest' social : - type : 'github' link : 'https://github.com/squidfunk' - type : 'twitter' link : 'https://twitter.com/squidfunk' - type : 'linkedin' link : 'https://linkedin.com/in/squidfunk' # Google Analytics google_analytics : - 'UA-XXXXXXXX-X' - 'auto' # Extensions markdown_extensions : - admonition - codehilite : guess_lang : false - toc : permalink : true","title":"Full example"},{"location":"license/","text":"License \u00b6 MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"release-notes/","text":"Seleksi Fitur \u00b6 Definisi \u00b6 Seleksi Fitur \u00b6 Seleksi fitur merupakan salah satu cara untuk mengurangi dimensi fitur yang sangat banyak. Seperti pada kasus kita, Text Mining, jumlah fitur yang didapatkan bisa mencapai lebih dari 2000 kata yang berbeda. Namun, tidak semua kata tersebut benar-benar berpengaruh pada hasil akhir nantinya. Selain itu, kita tahu bahwa semakin banyak data yang diproses, maka lebih banyak biaya dan waktu yang digunakan untuk memprosesnya. Oleh karena itu, kita perlu melakukan pengurangan fitur tanpa mengurangi kualitas hasil akhir, misalnya dengan Seleksi Fitur. Pada dasarnya, seleksi fitur memiliki 3 tipe umum: Wrap Filter Embed Selain itu, Seleksi Fitur juga memiliki banyak sekali metode-metode, seperti Information Gain, Chi Square, Pearson, dll. Pearson Correlation \u00b6 Pendekatan Pearson merupakan pendekatan paling sederhana. Pada pendekatan ini, setiap fitur akan dihitung korelasinya. Semakin tinggi nilainya, maka fitur tersebut semakin kuat korelasinya. Lalu fitur yang memiliki korelasi tinggi akan dibuang salah satunya. Code : def pearsonCalculate ( data , u , v ): \"i, j is an index\" atas = 0 ; bawah_kiri = 0 ; bawah_kanan = 0 for k in range ( len ( data )): atas += ( data [ k , u ] - meanFitur [ u ]) * ( data [ k , v ] - meanFitur [ v ]) bawah_kiri += ( data [ k , u ] - meanFitur [ u ]) ** 2 bawah_kanan += ( data [ k , v ] - meanFitur [ v ]) ** 2 bawah_kiri = bawah_kiri ** 0.5 bawah_kanan = bawah_kanan ** 0.5 return atas / ( bawah_kiri * bawah_kanan ) def meanF ( data ): meanFitur = [] for i in range ( len ( data [ 0 ])): meanFitur . append ( sum ( data [:, i ]) / len ( data )) return np . array ( meanFitur ) def seleksiFiturPearson ( data , threshold ): global meanFitur meanFitur = meanF ( data ) u = 0 while u < len ( data [ 0 ]): dataBaru = data [:, : u + 1 ] meanBaru = meanFitur [: u + 1 ] v = u while v < len ( data [ 0 ]): if u != v : value = pearsonCalculate ( data , u , v ) if value < threshold : dataBaru = np . hstack (( dataBaru , data [:, v ] . reshape ( data . shape [ 0 ], 1 ))) meanBaru = np . hstack (( meanBaru , meanFitur [ v ])) v += 1 data = dataBaru meanFitur = meanBaru if u % 50 == 0 : print ( u , data . shape ) u += 1 return data Chi Square \u00b6 Sama seperti pendekatan pearson, hanya saja, pendekatan ini lebih digunakan untuk data tipe categorical.","title":"Seleksi Fitur"},{"location":"release-notes/#seleksi-fitur","text":"","title":"Seleksi Fitur"},{"location":"release-notes/#definisi","text":"","title":"Definisi"},{"location":"release-notes/#seleksi-fitur_1","text":"Seleksi fitur merupakan salah satu cara untuk mengurangi dimensi fitur yang sangat banyak. Seperti pada kasus kita, Text Mining, jumlah fitur yang didapatkan bisa mencapai lebih dari 2000 kata yang berbeda. Namun, tidak semua kata tersebut benar-benar berpengaruh pada hasil akhir nantinya. Selain itu, kita tahu bahwa semakin banyak data yang diproses, maka lebih banyak biaya dan waktu yang digunakan untuk memprosesnya. Oleh karena itu, kita perlu melakukan pengurangan fitur tanpa mengurangi kualitas hasil akhir, misalnya dengan Seleksi Fitur. Pada dasarnya, seleksi fitur memiliki 3 tipe umum: Wrap Filter Embed Selain itu, Seleksi Fitur juga memiliki banyak sekali metode-metode, seperti Information Gain, Chi Square, Pearson, dll.","title":"Seleksi Fitur"},{"location":"release-notes/#pearson-correlation","text":"Pendekatan Pearson merupakan pendekatan paling sederhana. Pada pendekatan ini, setiap fitur akan dihitung korelasinya. Semakin tinggi nilainya, maka fitur tersebut semakin kuat korelasinya. Lalu fitur yang memiliki korelasi tinggi akan dibuang salah satunya. Code : def pearsonCalculate ( data , u , v ): \"i, j is an index\" atas = 0 ; bawah_kiri = 0 ; bawah_kanan = 0 for k in range ( len ( data )): atas += ( data [ k , u ] - meanFitur [ u ]) * ( data [ k , v ] - meanFitur [ v ]) bawah_kiri += ( data [ k , u ] - meanFitur [ u ]) ** 2 bawah_kanan += ( data [ k , v ] - meanFitur [ v ]) ** 2 bawah_kiri = bawah_kiri ** 0.5 bawah_kanan = bawah_kanan ** 0.5 return atas / ( bawah_kiri * bawah_kanan ) def meanF ( data ): meanFitur = [] for i in range ( len ( data [ 0 ])): meanFitur . append ( sum ( data [:, i ]) / len ( data )) return np . array ( meanFitur ) def seleksiFiturPearson ( data , threshold ): global meanFitur meanFitur = meanF ( data ) u = 0 while u < len ( data [ 0 ]): dataBaru = data [:, : u + 1 ] meanBaru = meanFitur [: u + 1 ] v = u while v < len ( data [ 0 ]): if u != v : value = pearsonCalculate ( data , u , v ) if value < threshold : dataBaru = np . hstack (( dataBaru , data [:, v ] . reshape ( data . shape [ 0 ], 1 ))) meanBaru = np . hstack (( meanBaru , meanFitur [ v ])) v += 1 data = dataBaru meanFitur = meanBaru if u % 50 == 0 : print ( u , data . shape ) u += 1 return data","title":"Pearson Correlation"},{"location":"release-notes/#chi-square","text":"Sama seperti pendekatan pearson, hanya saja, pendekatan ini lebih digunakan untuk data tipe categorical.","title":"Chi Square"},{"location":"specimen/","text":"Crawler \u00b6 Web Crawler \u00b6 adalah sebuah program dengan metode tertentu yang berfungsi untuk melakukan Scan atau crawl ke semua halaman internet untuk mencari data yang diinginkan. Data tersebut merupakan hasil teratas dari mesin pencari google dan yahoo. Web Crawler atau web spider, web robot, bot crawl dan automathic indeker. Web clawer memiliki beberapa maafaat dan tujuan tetapi penggunaan yang paling umum digunakan sebagai search engine. Search engine merupakan sebuah tool yang berfungsi sebagai mesin pencari seperti google. Ilustrasi : [ Headings \u00b6 The 3 rd level \u00b6 The 4 th level \u00b6 The 5 th level \u00b6 The 6 th level \u00b6 Headings with secondary text \u00b6 The 3 rd level with secondary text \u00b6 The 4 th level with secondary text \u00b6 The 5 th level with secondary text \u00b6 The 6 th level with secondary text \u00b6 Blockquotes \u00b6 Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Sed molestie imperdiet consectetur. Blockquote nesting \u00b6 Sed aliquet , neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem libero fermentum urna, ut efficitur elit ligula et nunc. Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. Suspendisse rutrum facilisis risus , eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa. Other content blocks \u00b6 Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Praesent at return target , sodales nibh vel, tempor felis. Fusce vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices. Donec consectetur mauris non neque imperdiet, eget volutpat libero. Lists \u00b6 Unordered lists \u00b6 Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris. Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Ordered lists \u00b6 Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Aliquam ornare feugiat quam et egestas. Nunc id erat et quam pellentesque lacinia eu vel odio. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Sed aliquet, neque at rutrum mollis, neque nisi tincidunt nibh. Pellentesque eget var _extends ornare tellus, ut gravida mi. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Definition lists \u00b6 Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris. Code blocks \u00b6 Inline \u00b6 Morbi eget dapibus felis . Vivamus venenatis porttitor tortor sit amet rutrum. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Pellentesque aliquet quam enim , eu volutpat urna rutrum a. Nam vehicula nunc return target mauris, a ultricies libero efficitur sed. Sed molestie imperdiet consectetur. Vivamus a pharetra leo. Pellentesque eget ornare tellus, ut gravida mi. Fusce vel lacinia lacus. Listing \u00b6 1 2 3 4 5 6 7 8 9 var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Horizontal rules \u00b6 Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales. Data tables \u00b6 Sollicitudo / Pellentesi consectetur adipiscing elit arcu sed Vivamus a pharetra yes yes yes yes yes Ornare viverra ex yes yes yes yes yes Mauris a ullamcorper yes yes partial yes yes Nullam urna elit yes yes yes yes yes Malesuada eget finibus yes yes yes yes yes Ullamcorper yes yes yes yes yes Vestibulum sodales yes - yes - yes Pulvinar nisl yes yes yes - - Pharetra aliquet est yes yes yes yes yes Sed suscipit yes yes yes yes yes Orci non pretium yes partial - - - Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Left Center Right Lorem dolor amet ipsum sit Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. Table with colgroups (Pandoc) Lorem ipsum dolor sit amet. Sed sagittis eleifend rutrum. Donec vitae suscipit est.","title":"Crawler"},{"location":"specimen/#crawler","text":"","title":"Crawler"},{"location":"specimen/#web-crawler","text":"adalah sebuah program dengan metode tertentu yang berfungsi untuk melakukan Scan atau crawl ke semua halaman internet untuk mencari data yang diinginkan. Data tersebut merupakan hasil teratas dari mesin pencari google dan yahoo. Web Crawler atau web spider, web robot, bot crawl dan automathic indeker. Web clawer memiliki beberapa maafaat dan tujuan tetapi penggunaan yang paling umum digunakan sebagai search engine. Search engine merupakan sebuah tool yang berfungsi sebagai mesin pencari seperti google. Ilustrasi : [","title":"Web Crawler"},{"location":"specimen/#headings","text":"","title":"Headings"},{"location":"specimen/#the-3rd-level","text":"","title":"The 3rd level"},{"location":"specimen/#the-4th-level","text":"","title":"The 4th level"},{"location":"specimen/#the-5th-level","text":"","title":"The 5th level"},{"location":"specimen/#the-6th-level","text":"","title":"The 6th level"},{"location":"specimen/#headings-with-secondary-text","text":"","title":"Headings with secondary text"},{"location":"specimen/#the-3rd-level-with-secondary-text","text":"","title":"The 3rd level with secondary text"},{"location":"specimen/#the-4th-level-with-secondary-text","text":"","title":"The 4th level with secondary text"},{"location":"specimen/#the-5th-level-with-secondary-text","text":"","title":"The 5th level with secondary text"},{"location":"specimen/#the-6th-level-with-secondary-text","text":"","title":"The 6th level with secondary text"},{"location":"specimen/#blockquotes","text":"Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Sed molestie imperdiet consectetur.","title":"Blockquotes"},{"location":"specimen/#blockquote-nesting","text":"Sed aliquet , neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem libero fermentum urna, ut efficitur elit ligula et nunc. Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. Suspendisse rutrum facilisis risus , eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa.","title":"Blockquote nesting"},{"location":"specimen/#other-content-blocks","text":"Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Praesent at return target , sodales nibh vel, tempor felis. Fusce vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices. Donec consectetur mauris non neque imperdiet, eget volutpat libero.","title":"Other content blocks"},{"location":"specimen/#lists","text":"","title":"Lists"},{"location":"specimen/#unordered-lists","text":"Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris. Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam.","title":"Unordered lists"},{"location":"specimen/#ordered-lists","text":"Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Aliquam ornare feugiat quam et egestas. Nunc id erat et quam pellentesque lacinia eu vel odio. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Sed aliquet, neque at rutrum mollis, neque nisi tincidunt nibh. Pellentesque eget var _extends ornare tellus, ut gravida mi. var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; }; Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo.","title":"Ordered lists"},{"location":"specimen/#definition-lists","text":"Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris.","title":"Definition lists"},{"location":"specimen/#code-blocks","text":"","title":"Code blocks"},{"location":"specimen/#inline","text":"Morbi eget dapibus felis . Vivamus venenatis porttitor tortor sit amet rutrum. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Pellentesque aliquet quam enim , eu volutpat urna rutrum a. Nam vehicula nunc return target mauris, a ultricies libero efficitur sed. Sed molestie imperdiet consectetur. Vivamus a pharetra leo. Pellentesque eget ornare tellus, ut gravida mi. Fusce vel lacinia lacus.","title":"Inline"},{"location":"specimen/#listing","text":"1 2 3 4 5 6 7 8 9 var _extends = function ( target ) { for ( var i = 1 ; i < arguments . length ; i ++ ) { var source = arguments [ i ]; for ( var key in source ) { target [ key ] = source [ key ]; } } return target ; };","title":"Listing"},{"location":"specimen/#horizontal-rules","text":"Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales.","title":"Horizontal rules"},{"location":"specimen/#data-tables","text":"Sollicitudo / Pellentesi consectetur adipiscing elit arcu sed Vivamus a pharetra yes yes yes yes yes Ornare viverra ex yes yes yes yes yes Mauris a ullamcorper yes yes partial yes yes Nullam urna elit yes yes yes yes yes Malesuada eget finibus yes yes yes yes yes Ullamcorper yes yes yes yes yes Vestibulum sodales yes - yes - yes Pulvinar nisl yes yes yes - - Pharetra aliquet est yes yes yes yes yes Sed suscipit yes yes yes yes yes Orci non pretium yes partial - - - Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Left Center Right Lorem dolor amet ipsum sit Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. Table with colgroups (Pandoc) Lorem ipsum dolor sit amet. Sed sagittis eleifend rutrum. Donec vitae suscipit est.","title":"Data tables"},{"location":"extensions/admonition/","text":"Web Structure Mining \u00b6 Abstrak: Karena meningkatnya jumlah data yang tersedia secara online, World Wide Web telah menjadi salah satu sumber daya paling berharga untuk pengambilan informasi dan penemuan pengetahuan. Teknologi penambangan web adalah solusi yang tepat untuk penemuan pengetahuan di Web. Pengetahuan yang diekstraksi dari Web dapat digunakan untuk meningkatkan kinerja untuk pencarian informasi Web, menjawab pertanyaan, dan penyimpanan data berbasis web. Dalam makalah ini, kami menyediakan pengantar penambangan Web serta peninjauan kategori penambangan Web. Kemudian fokus pada salah satu kategori ini: penambangan struktur Web. Dalam kategori ini, akan memperkenalkan penambangan tautan dan meninjau metode populer yang diterapkan dalam penambangan struktur Web: PageRank. Web struncture mining dikenal juga sebagai web log mining adalah teknik yang digunakan untuk menemukan struktur link dari hyperlink dan membangun rangkuman website dan halaman web. Salah satu manfaatnya adlah untuk menentukan pagerank pada suatu halaman web. Code \u00b6 Berikut Kode Utama Untuk Melakukan Crawling, mengunakan library requests dan BeautifulSoup4 : def getAllLinks ( src ): try : page = requests . get ( src ) soup = BeautifulSoup ( page . content , 'html.parser' ) tags = soup . findAll ( \"a\" ) links = [] for tag in tags : try : link = tag [ 'href' ] if not link in links and 'http' in link : links . append ( link ) except KeyError : pass return links except : return list () Program Di atas digunakan untuk mengambil semua link yang ada pada sebuah website pertama yang di crawl, Kemudian Untuk Mendapatkan crawling secara berulang , definisikan sebuah fungsi crawl : def simplifiedURL ( url ): # cek 1 : www if \"www.\" in url : ind = url . index ( \"www.\" ) + 4 url = \"http://\" + url [ ind :] # cek 3 : tanda / di akhir if url [ - 1 ] == \"/\" : url = url [: - 1 ] # Cek 4 : cuma domain utama parts = url . split ( \"/\" ) url = '' for i in range ( 3 ): url += parts [ i ] + \"/\" return url def crawl ( url , max_deep , show = False , deep = 0 , done = []): global edgelist deep += 1 url = simplifiedURL ( url ) if not url in done : links = getAllLinks ( url ) done . append ( url ) if show : if deep == 1 : print ( url ) else : print ( \"|\" , end = \"\" ) for i in range ( deep - 1 ): print ( \"--\" , end = \"\" ) print ( url ) for link in links : link = simplifiedURL ( link ) edge = ( url , link ) if not edge in edgelist : edgelist . append ( edge ) if ( deep != max_deep ): crawl ( link , max_deep , show , deep , done ) Method simplifiedURL berfungsi untuk menyamakan semua format url, menjadi http://urlweb.com/ Proses pemanggilan method di atas bisa dilakukan dengan cara berikut: import requests import pandas as pd from bs4 import BeautifulSoup # Inisialisasi variabel root = \"https://www.liputan6.com/\" nodelist = [ root ] edgelist = [] #crawl crawl ( root , 3 , show = True ) edgelistFrame = pd . DataFrame ( edgelist , None , ( \"From\" , \"To\" ))","title":"Web Structure Mining"},{"location":"extensions/admonition/#web-structure-mining","text":"Abstrak: Karena meningkatnya jumlah data yang tersedia secara online, World Wide Web telah menjadi salah satu sumber daya paling berharga untuk pengambilan informasi dan penemuan pengetahuan. Teknologi penambangan web adalah solusi yang tepat untuk penemuan pengetahuan di Web. Pengetahuan yang diekstraksi dari Web dapat digunakan untuk meningkatkan kinerja untuk pencarian informasi Web, menjawab pertanyaan, dan penyimpanan data berbasis web. Dalam makalah ini, kami menyediakan pengantar penambangan Web serta peninjauan kategori penambangan Web. Kemudian fokus pada salah satu kategori ini: penambangan struktur Web. Dalam kategori ini, akan memperkenalkan penambangan tautan dan meninjau metode populer yang diterapkan dalam penambangan struktur Web: PageRank. Web struncture mining dikenal juga sebagai web log mining adalah teknik yang digunakan untuk menemukan struktur link dari hyperlink dan membangun rangkuman website dan halaman web. Salah satu manfaatnya adlah untuk menentukan pagerank pada suatu halaman web.","title":"Web Structure Mining"},{"location":"extensions/admonition/#code","text":"Berikut Kode Utama Untuk Melakukan Crawling, mengunakan library requests dan BeautifulSoup4 : def getAllLinks ( src ): try : page = requests . get ( src ) soup = BeautifulSoup ( page . content , 'html.parser' ) tags = soup . findAll ( \"a\" ) links = [] for tag in tags : try : link = tag [ 'href' ] if not link in links and 'http' in link : links . append ( link ) except KeyError : pass return links except : return list () Program Di atas digunakan untuk mengambil semua link yang ada pada sebuah website pertama yang di crawl, Kemudian Untuk Mendapatkan crawling secara berulang , definisikan sebuah fungsi crawl : def simplifiedURL ( url ): # cek 1 : www if \"www.\" in url : ind = url . index ( \"www.\" ) + 4 url = \"http://\" + url [ ind :] # cek 3 : tanda / di akhir if url [ - 1 ] == \"/\" : url = url [: - 1 ] # Cek 4 : cuma domain utama parts = url . split ( \"/\" ) url = '' for i in range ( 3 ): url += parts [ i ] + \"/\" return url def crawl ( url , max_deep , show = False , deep = 0 , done = []): global edgelist deep += 1 url = simplifiedURL ( url ) if not url in done : links = getAllLinks ( url ) done . append ( url ) if show : if deep == 1 : print ( url ) else : print ( \"|\" , end = \"\" ) for i in range ( deep - 1 ): print ( \"--\" , end = \"\" ) print ( url ) for link in links : link = simplifiedURL ( link ) edge = ( url , link ) if not edge in edgelist : edgelist . append ( edge ) if ( deep != max_deep ): crawl ( link , max_deep , show , deep , done ) Method simplifiedURL berfungsi untuk menyamakan semua format url, menjadi http://urlweb.com/ Proses pemanggilan method di atas bisa dilakukan dengan cara berikut: import requests import pandas as pd from bs4 import BeautifulSoup # Inisialisasi variabel root = \"https://www.liputan6.com/\" nodelist = [ root ] edgelist = [] #crawl crawl ( root , 3 , show = True ) edgelistFrame = pd . DataFrame ( edgelist , None , ( \"From\" , \"To\" ))","title":"Code"},{"location":"extensions/codehilite/","text":"Graph \u00b6 Grafik adalah struktur data non-linear yang terdiri dari node dan edge. Node kadang-kadang juga disebut sebagai simpul dan ujungnya adalah garis atau busur yang menghubungkan dua node dalam grafik. Pada Web Structure Mining, Graph Berarah (directed graph) digunakan untuk menggambarkan hubungan suatu web. Beberapa terminology yang digunakan di Web Structure Mining Code \u00b6 Proses pembuatan Graph pada Python bisa dilakukan dengan mudah menggunakan library networkx dan mathplotlib untuk menampilkannya. import networkx as nx import networkx as nx #membuat Graph g = nx . from_pandas_edgelist ( edgelistFrame , \"From\" , \"To\" , None , nx . DiGraph ()) # deklarasi pos (koordinat) (otomatis) pos = nx . spring_layout ( g ) # Membuat Label && print pagerank print ( \"keterangan node:\" ) nodelist = g . nodes label = {} data = [] for i , key in enumerate ( nodelist ): data . append (( pr [ key ], key )) label [ key ] = i print ( i , key , pr [ key ]) data = pd . DataFrame ( data , None , ( \"PageRank\" , \"Node\" )) # Draw Graph #plt.figure(1) #plt.title('circle_layout') nx . draw ( g , pos ) nx . draw_networkx_labels ( g , pos , label , font_color = \"b\" ) # show figure plt . axis ( \"off\" ) plt . show () Pertama membuat sebuah Graph berarah dengan memanggil g = nx.Graph() lalu g = g.to_directed() . Lalu untuk memasukkan daftar edge yang telah dibuat ke graph,menggunakan .from_pandas_edgelist dengan paraeter berturut-turut pandas.DataFrame, nama_kolom_sumber, nama_kolom_tujuan, edge_attribut, dan jenis_graph. Kemuidan mendefinisikan letak dari setiap node menggunakan layout yang tersedia di networkx, seperti nx.spring_layout(g) . Untuk menampilkan graph, menggunakan method nx.draw(graph, pos) . Kemudian `plt.show()","title":"Graph"},{"location":"extensions/codehilite/#graph","text":"Grafik adalah struktur data non-linear yang terdiri dari node dan edge. Node kadang-kadang juga disebut sebagai simpul dan ujungnya adalah garis atau busur yang menghubungkan dua node dalam grafik. Pada Web Structure Mining, Graph Berarah (directed graph) digunakan untuk menggambarkan hubungan suatu web. Beberapa terminology yang digunakan di Web Structure Mining","title":"Graph"},{"location":"extensions/codehilite/#code","text":"Proses pembuatan Graph pada Python bisa dilakukan dengan mudah menggunakan library networkx dan mathplotlib untuk menampilkannya. import networkx as nx import networkx as nx #membuat Graph g = nx . from_pandas_edgelist ( edgelistFrame , \"From\" , \"To\" , None , nx . DiGraph ()) # deklarasi pos (koordinat) (otomatis) pos = nx . spring_layout ( g ) # Membuat Label && print pagerank print ( \"keterangan node:\" ) nodelist = g . nodes label = {} data = [] for i , key in enumerate ( nodelist ): data . append (( pr [ key ], key )) label [ key ] = i print ( i , key , pr [ key ]) data = pd . DataFrame ( data , None , ( \"PageRank\" , \"Node\" )) # Draw Graph #plt.figure(1) #plt.title('circle_layout') nx . draw ( g , pos ) nx . draw_networkx_labels ( g , pos , label , font_color = \"b\" ) # show figure plt . axis ( \"off\" ) plt . show () Pertama membuat sebuah Graph berarah dengan memanggil g = nx.Graph() lalu g = g.to_directed() . Lalu untuk memasukkan daftar edge yang telah dibuat ke graph,menggunakan .from_pandas_edgelist dengan paraeter berturut-turut pandas.DataFrame, nama_kolom_sumber, nama_kolom_tujuan, edge_attribut, dan jenis_graph. Kemuidan mendefinisikan letak dari setiap node menggunakan layout yang tersedia di networkx, seperti nx.spring_layout(g) . Untuk menampilkan graph, menggunakan method nx.draw(graph, pos) . Kemudian `plt.show()","title":"Code"},{"location":"extensions/footnotes/","text":"PageRank PageRank adalah sebuah algoritme yang telah dipatenkan yang berfungsi menentukan situs web mana yang lebih penting/populer. PageRank merupakan salah satu fitur utama mesin pencari Google dan diciptakan oleh pendirinya, Larry Page dan Sergey Brin yang merupakan mahasiswa Ph.D. Universitas Stanford . Algoritma \u00b6 Dari pendekatan yang sudah dijelaskan pada artikel konsep pagerank , Lawrence Page and Sergey Brin membuat algoritme pagerank seperti di bawah: Algoritme awal Salah satu algoritme lain yang dipublikasikan PR(A) adalah Pagerank halaman A PR(T1) adalah Pagerank halaman T1 yang mengacu ke halaman A C(T1) adalah jumlah link keluar ( outbound link ) pada halaman T1 d adalah damping factor yang bisa diberi antara 0 dan 1. N adalah jumlah keseluruhan halaman web (yang terindeks oleh Google) Dari algoritme di atas dapat dilihat bahwa pagerank ditentukan untuk setiap halaman anda bukan keseluruhan situs web. Pagerank sebuah halaman ditentukan dari pagerank halaman yang mengacu kepadanya yang juga menjalani proses penentuan pagerank dengan cara yang sama, jadi proses ini akan berulang sampai ditemukan hasil yang tepat. Akan tetapi pagerank halaman A tidak langsung diberikan kepada halaman yang dituju, akan tetapi sebelumnya dibagi dengan jumlah link yang ada pada halaman T1 (outbound link), dan pagerank itu akan dibagi rata kepada setiap link yang ada pada halaman tersebut. Demikian juga dengan setiap halaman lain \u201cTn\u201d yang mengacu ke halaman \u201cA\u201d. Setelah semua pagerank yang didapat dari halaman-halaman lain yang mengacu ke halaman \u201cA\u201d dijumlahkan, nilai itu kemudian dikalikan dengan damping factor yang bernilai antara 0 sampai 1. Hal ini dilakukan agar tidak keseluruhan nilai pagerank halaman T didistribusikan ke halaman A. Konsep \u00b6 Banyak cara digunakan search engine dalam menentukan kualitas/rangking sebuah halaman web, mulai dari penggunaan META Tags , isi dokumen, penekanan pada content dan masih banyak teknik lain atau gabungan teknik yang mungkin digunakan. Link popularity , sebuah teknologi yang dikembangkan untuk memperbaiki kekurangan dari teknologi lain ( Meta Keywords, Meta Description ) yang bisa dicurangi dengan halaman yang khusus di desain untuk search engine atau biasa disebut doorway pages . Dengan algoritme \u2018 PageRank \u2019 ini, dalam setiap halaman akan diperhitungkan inbound link (link masuk) dan outbound link (link keuar) dari setiap halaman web. PageRank , memiliki konsep dasar yang sama dengan link popularity , tetapi tidak hanya memperhitungkan \u201cjumlah\u201d inbound dan outbound link . Pendekatan yang digunakan adalah sebuah halaman akan diangap penting jika halaman lain memiliki link ke halaman tersebut. Sebuah halaman juga akan menjadi semakin penting jika halaman lain yang memiliki rangking (pagerank) tinggi mengacu ke halaman tersebut. Dengan pendekatan yang digunakan PageRank , proses terjadi secara rekursif dimana sebuah rangking akan ditentukan oleh rangking dari halaman web yang rangkingnya ditentukan oleh rangking halaman web lain yang memiliki link ke halaman tersebut. Proses ini berarti suatu proses yang berulang (rekursif). Di dunia maya, ada jutaan bahkan milyaran halaman web. Oleh karena itu sebuah rangking halaman web ditentukan dari struktur link dari keseluruhan halaman web yang ada di dunia maya. Sebuah proses yang sangat besar dan komplek. Code : import networkx as nx # hitung pagerank damping = 0.85 max_iterr = 100 error_toleransi = 0.0001 pr = nx . pagerank ( g , alpha = damping , max_iter = max_iterr , tol = error_toleransi )","title":"PageRank"},{"location":"extensions/footnotes/#algoritma","text":"Dari pendekatan yang sudah dijelaskan pada artikel konsep pagerank , Lawrence Page and Sergey Brin membuat algoritme pagerank seperti di bawah: Algoritme awal Salah satu algoritme lain yang dipublikasikan PR(A) adalah Pagerank halaman A PR(T1) adalah Pagerank halaman T1 yang mengacu ke halaman A C(T1) adalah jumlah link keluar ( outbound link ) pada halaman T1 d adalah damping factor yang bisa diberi antara 0 dan 1. N adalah jumlah keseluruhan halaman web (yang terindeks oleh Google) Dari algoritme di atas dapat dilihat bahwa pagerank ditentukan untuk setiap halaman anda bukan keseluruhan situs web. Pagerank sebuah halaman ditentukan dari pagerank halaman yang mengacu kepadanya yang juga menjalani proses penentuan pagerank dengan cara yang sama, jadi proses ini akan berulang sampai ditemukan hasil yang tepat. Akan tetapi pagerank halaman A tidak langsung diberikan kepada halaman yang dituju, akan tetapi sebelumnya dibagi dengan jumlah link yang ada pada halaman T1 (outbound link), dan pagerank itu akan dibagi rata kepada setiap link yang ada pada halaman tersebut. Demikian juga dengan setiap halaman lain \u201cTn\u201d yang mengacu ke halaman \u201cA\u201d. Setelah semua pagerank yang didapat dari halaman-halaman lain yang mengacu ke halaman \u201cA\u201d dijumlahkan, nilai itu kemudian dikalikan dengan damping factor yang bernilai antara 0 sampai 1. Hal ini dilakukan agar tidak keseluruhan nilai pagerank halaman T didistribusikan ke halaman A.","title":"Algoritma"},{"location":"extensions/footnotes/#konsep","text":"Banyak cara digunakan search engine dalam menentukan kualitas/rangking sebuah halaman web, mulai dari penggunaan META Tags , isi dokumen, penekanan pada content dan masih banyak teknik lain atau gabungan teknik yang mungkin digunakan. Link popularity , sebuah teknologi yang dikembangkan untuk memperbaiki kekurangan dari teknologi lain ( Meta Keywords, Meta Description ) yang bisa dicurangi dengan halaman yang khusus di desain untuk search engine atau biasa disebut doorway pages . Dengan algoritme \u2018 PageRank \u2019 ini, dalam setiap halaman akan diperhitungkan inbound link (link masuk) dan outbound link (link keuar) dari setiap halaman web. PageRank , memiliki konsep dasar yang sama dengan link popularity , tetapi tidak hanya memperhitungkan \u201cjumlah\u201d inbound dan outbound link . Pendekatan yang digunakan adalah sebuah halaman akan diangap penting jika halaman lain memiliki link ke halaman tersebut. Sebuah halaman juga akan menjadi semakin penting jika halaman lain yang memiliki rangking (pagerank) tinggi mengacu ke halaman tersebut. Dengan pendekatan yang digunakan PageRank , proses terjadi secara rekursif dimana sebuah rangking akan ditentukan oleh rangking dari halaman web yang rangkingnya ditentukan oleh rangking halaman web lain yang memiliki link ke halaman tersebut. Proses ini berarti suatu proses yang berulang (rekursif). Di dunia maya, ada jutaan bahkan milyaran halaman web. Oleh karena itu sebuah rangking halaman web ditentukan dari struktur link dari keseluruhan halaman web yang ada di dunia maya. Sebuah proses yang sangat besar dan komplek. Code : import networkx as nx # hitung pagerank damping = 0.85 max_iterr = 100 error_toleransi = 0.0001 pr = nx . pagerank ( g , alpha = damping , max_iter = max_iterr , tol = error_toleransi )","title":"Konsep"},{"location":"extensions/metadata/","text":"Hasil Program \u00b6 Ketika program dijalankan, maka program akan mendownload halaman web dan mencari semua link yang ada pada halaman tersebut. Semua link yang didapat akan dilakukan proses crawling kembali dan dicatat. Program melakukan proses Web Structure Mining dengan alamat awal \" https://www.liputan6.com/ \" [ Detail Node Page rank: \u00b6 No Doc Nama Website PageRank 0 http://liputan6.com/ 0.01430185490306184 1 https://hot.liputan6.com/ 0.00868912422859208 2 http://vidio.com/ 0.012468953255907887 3 http://support.vidio.com/ 0.010241327849761585 4 http://kmklabs.com/ 0.010241327849761585 5 http://m.vidio.com/ 0.010241327849761585 6 http://facebook.com/ 0.018947496139838687 7 https://en-gb.facebook.com/ 0.00872249544838987 8 https://jv-id.facebook.com/ 0.00872249544838987 9 https://ms-my.facebook.com/ 0.00872249544838987 10 https://ja-jp.facebook.com/ 0.00872249544838987 11 https://ar-ar.facebook.com/ 0.00872249544838987 12 https://fr-fr.facebook.com/ 0.00872249544838987 13 https://es-la.facebook.com/ 0.00872249544838987 14 https://ko-kr.facebook.com/ 0.00872249544838987 15 https://pt-br.facebook.com/ 0.00872249544838987 16 https://de-de.facebook.com/ 0.00872249544838987 17 https://messenger.com/ 0.00872249544838987 18 https://l.facebook.com/ 0.00872249544838987 19 https://developers.facebook.com/ 0.00872249544838987 20 http://twitter.com/ 0.011517500017515878 21 https://twitter.com/ 0.015560658501019339 As describe in the [getting started guide][], the Disqus comments section can be enabled on a per-document level:","title":"Hasil Output"},{"location":"extensions/metadata/#hasil-program","text":"Ketika program dijalankan, maka program akan mendownload halaman web dan mencari semua link yang ada pada halaman tersebut. Semua link yang didapat akan dilakukan proses crawling kembali dan dicatat. Program melakukan proses Web Structure Mining dengan alamat awal \" https://www.liputan6.com/ \" [","title":"Hasil Program"},{"location":"extensions/metadata/#detail-node-page-rank","text":"No Doc Nama Website PageRank 0 http://liputan6.com/ 0.01430185490306184 1 https://hot.liputan6.com/ 0.00868912422859208 2 http://vidio.com/ 0.012468953255907887 3 http://support.vidio.com/ 0.010241327849761585 4 http://kmklabs.com/ 0.010241327849761585 5 http://m.vidio.com/ 0.010241327849761585 6 http://facebook.com/ 0.018947496139838687 7 https://en-gb.facebook.com/ 0.00872249544838987 8 https://jv-id.facebook.com/ 0.00872249544838987 9 https://ms-my.facebook.com/ 0.00872249544838987 10 https://ja-jp.facebook.com/ 0.00872249544838987 11 https://ar-ar.facebook.com/ 0.00872249544838987 12 https://fr-fr.facebook.com/ 0.00872249544838987 13 https://es-la.facebook.com/ 0.00872249544838987 14 https://ko-kr.facebook.com/ 0.00872249544838987 15 https://pt-br.facebook.com/ 0.00872249544838987 16 https://de-de.facebook.com/ 0.00872249544838987 17 https://messenger.com/ 0.00872249544838987 18 https://l.facebook.com/ 0.00872249544838987 19 https://developers.facebook.com/ 0.00872249544838987 20 http://twitter.com/ 0.011517500017515878 21 https://twitter.com/ 0.015560658501019339 As describe in the [getting started guide][], the Disqus comments section can be enabled on a per-document level:","title":"Detail Node Page rank:"},{"location":"extensions/permalinks/","text":"Permalinks \u00b6 Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document. Installation \u00b6 To enable permalinks, add the following to your mkdocs.yml : markdown_extensions : - toc : permalink : true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link Usage \u00b6 When enabled, permalinks are inserted automatically.","title":"Permalinks"},{"location":"extensions/permalinks/#permalinks","text":"Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document.","title":"Permalinks"},{"location":"extensions/permalinks/#installation","text":"To enable permalinks, add the following to your mkdocs.yml : markdown_extensions : - toc : permalink : true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link","title":"Installation"},{"location":"extensions/permalinks/#usage","text":"When enabled, permalinks are inserted automatically.","title":"Usage"},{"location":"extensions/pymdown/","text":"PyMdown Extensions \u00b6 PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme. Installation \u00b6 The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions : - pymdownx.arithmatex - pymdownx.betterem : smart_enable : all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji : emoji_generator : !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist : custom_checkbox : true - pymdownx.tilde Usage \u00b6 Arithmatex MathJax \u00b6 Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript : - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window . MathJax = { tex2jax : { inlineMath : [ [ \"\\\\(\" , \"\\\\)\" ] ], displayMath : [ [ \"\\\\[\" , \"\\\\]\" ] ] }, TeX : { TagSide : \"right\" , TagIndent : \".8em\" , MultLineWidth : \"85%\" , equationNumbers : { autoNumber : \"AMS\" , }, unicode : { fonts : \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign : \"left\" , showProcessingMessages : false , messageStyle : \"none\" }; In your mkdocs.yml , include it with: extra_javascript : - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' Blocks \u00b6 Blocks are enclosed in $$ ... $$ which are placed on separate lines. Example: $$ \\frac {n ! }{k !( n - k )! } = \\binom {n}{k} $$ Result: \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k} Inline \u00b6 Inline equations need to be enclosed in $ ... $ : Example: Lorem ipsum dolor sit amet: $ p ( x|y ) = \\frac {p ( y|x ) p ( x ) }{p ( y ) } $ Result: Lorem ipsum dolor sit amet: p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} BetterEm \u00b6 BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes . Caret \u00b6 Caret makes it possible to highlight inserted text . The portion of text that should be marked as added must be enclosed in two carets ^^...^^ . Critic \u00b6 Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. Details \u00b6 Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: How many Prolog programmers does it take to change a lightbulb? Yes. Emoji \u00b6 Emoji adds the ability to insert a -load of emojis that we use in our daily lives. See the EmojiOne demo for a list of all available emojis. Happy scrolling Legal disclaimer Material has no affiliation with EmojiOne which is released under CC BY 4.0 . When including EmojiOne images or CSS, please read the EmojiOne license to ensure proper usage and attribution. InlineHilite \u00b6 InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. var test = 0 ; and can be achived by prefixing inline code with a shebang and language identifier, e.g. #!js . MagicLink \u00b6 MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses. Mark \u00b6 Mark adds the ability to highlight text like it was marked with a text marker . The portion of text that should be highlighted must be enclosed in two equal signs ==...== . SmartSymbols \u00b6 SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (\u2190, \u2192, \u2194), trademark and copyright symbols (\u00a9, \u2122, \u00ae) and fractions (\u00bd, \u00bc, ...). SuperFences \u00b6 SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs . Tasklist \u00b6 Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit Nulla lobortis egestas semper Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Sed egestas felis quis elit dapibus, ac aliquet turpis mattis Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Tilde \u00b6 Tilde provides an easy way to strike through cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"PyMdown Extensions"},{"location":"extensions/pymdown/#pymdown-extensions","text":"PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme.","title":"PyMdown Extensions"},{"location":"extensions/pymdown/#installation","text":"The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions : - pymdownx.arithmatex - pymdownx.betterem : smart_enable : all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji : emoji_generator : !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist : custom_checkbox : true - pymdownx.tilde","title":"Installation"},{"location":"extensions/pymdown/#usage","text":"","title":"Usage"},{"location":"extensions/pymdown/#arithmatex-mathjax","text":"Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript : - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window . MathJax = { tex2jax : { inlineMath : [ [ \"\\\\(\" , \"\\\\)\" ] ], displayMath : [ [ \"\\\\[\" , \"\\\\]\" ] ] }, TeX : { TagSide : \"right\" , TagIndent : \".8em\" , MultLineWidth : \"85%\" , equationNumbers : { autoNumber : \"AMS\" , }, unicode : { fonts : \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign : \"left\" , showProcessingMessages : false , messageStyle : \"none\" }; In your mkdocs.yml , include it with: extra_javascript : - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML'","title":"Arithmatex MathJax"},{"location":"extensions/pymdown/#blocks","text":"Blocks are enclosed in $$ ... $$ which are placed on separate lines. Example: $$ \\frac {n ! }{k !( n - k )! } = \\binom {n}{k} $$ Result: \\frac{n!}{k!(n-k)!} = \\binom{n}{k} \\frac{n!}{k!(n-k)!} = \\binom{n}{k}","title":"Blocks"},{"location":"extensions/pymdown/#inline","text":"Inline equations need to be enclosed in $ ... $ : Example: Lorem ipsum dolor sit amet: $ p ( x|y ) = \\frac {p ( y|x ) p ( x ) }{p ( y ) } $ Result: Lorem ipsum dolor sit amet: p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)}","title":"Inline"},{"location":"extensions/pymdown/#betterem","text":"BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes .","title":"BetterEm"},{"location":"extensions/pymdown/#caret","text":"Caret makes it possible to highlight inserted text . The portion of text that should be marked as added must be enclosed in two carets ^^...^^ .","title":"Caret"},{"location":"extensions/pymdown/#critic","text":"Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be deleted and replacement text added . This can also be combined into one a single operation. Highlighting is also possible and comments can be added inline . Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content.","title":"Critic"},{"location":"extensions/pymdown/#details","text":"Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: How many Prolog programmers does it take to change a lightbulb? Yes.","title":"Details"},{"location":"extensions/pymdown/#emoji","text":"Emoji adds the ability to insert a -load of emojis that we use in our daily lives. See the EmojiOne demo for a list of all available emojis. Happy scrolling Legal disclaimer Material has no affiliation with EmojiOne which is released under CC BY 4.0 . When including EmojiOne images or CSS, please read the EmojiOne license to ensure proper usage and attribution.","title":"Emoji"},{"location":"extensions/pymdown/#inlinehilite","text":"InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. var test = 0 ; and can be achived by prefixing inline code with a shebang and language identifier, e.g. #!js .","title":"InlineHilite"},{"location":"extensions/pymdown/#magiclink","text":"MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses.","title":"MagicLink"},{"location":"extensions/pymdown/#mark","text":"Mark adds the ability to highlight text like it was marked with a text marker . The portion of text that should be highlighted must be enclosed in two equal signs ==...== .","title":"Mark"},{"location":"extensions/pymdown/#smartsymbols","text":"SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (\u2190, \u2192, \u2194), trademark and copyright symbols (\u00a9, \u2122, \u00ae) and fractions (\u00bd, \u00bc, ...).","title":"SmartSymbols"},{"location":"extensions/pymdown/#superfences","text":"SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs .","title":"SuperFences"},{"location":"extensions/pymdown/#tasklist","text":"Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit Nulla lobortis egestas semper Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Sed egestas felis quis elit dapibus, ac aliquet turpis mattis Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Nulla vel eros venenatis, imperdiet enim id, faucibus nisi","title":"Tasklist"},{"location":"extensions/pymdown/#tilde","text":"Tilde provides an easy way to strike through cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"Tilde"}]}